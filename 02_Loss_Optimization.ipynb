{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526cc309",
   "metadata": {},
   "source": [
    "<b>tasks:</b>\n",
    "1) Create Logistic Regression Class without using SKlearn methods\n",
    "\n",
    "2) Create Gradient Descent\n",
    "\n",
    "3) Create RMSProp\n",
    "\n",
    "4) Nesterov–accelerated Adaptive Moment Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a059b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4aafac3",
   "metadata": {},
   "source": [
    "### Own class LogisticRegression:\n",
    "\n",
    "- own basics methods: fit, predict, score\n",
    "\n",
    "- method of optimizing is Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "21fef283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class LogisticRegression \n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, epoches=20, learning_rate=0.0001):\n",
    "        self.EPOCHS = epoches               # Количество эпох\n",
    "        self.LEARNING_RATE = learning_rate  # Скорость обучения\n",
    "        \n",
    "        self.costs = []    # массив оценок MSE\n",
    "        self.params = []   # массив параметров\n",
    "        self.preds = []    # массив предсказаний\n",
    "        self.list_params_gd = []\n",
    "        \n",
    "        self.threashold = 0.5\n",
    "        \n",
    "        \n",
    "    #sigmoid function (функция активации от x)\n",
    "    def sigm(self, X, W):\n",
    "        return 1/(1 + np.exp(-np.dot(X.T,W)))\n",
    "    \n",
    "    \n",
    "    #Optimizing by GD\n",
    "    def fit(self, Y, X):\n",
    "        # X + нулевой вес\n",
    "        X_np = np.c_[np.array(X), np.ones(len(X))].T       # X в numpy массив [5x100]\n",
    "        \n",
    "        Y_np = np.asmatrix(Y).T\n",
    "        \n",
    "        # Начальное приближение весов\n",
    "        W = np.random.normal(size=(X_np.shape[0],1), loc=1, scale=0)     # Матричца весов [5x1]\n",
    "        \n",
    "        # создание копии, т.к. иначе будем перезапиывать по ссылке\n",
    "        self.list_params_gd = [W.copy()]\n",
    "\n",
    "        for _ in range(self.EPOCHS):\n",
    "            predictions = sigm(X_np, W)\n",
    "            self.preds.append(predictions)\n",
    "            \n",
    "            cost = self.logloss(X_np, Y_np, W)\n",
    "            self.costs.append(cost)\n",
    "            \n",
    "            #формулу градиента: взял отсюда https://habr.com/ru/articles/472300/\n",
    "            grad = X_np*(Y_np - self.sigm(X_np, W))\n",
    "            W -= -self.LEARNING_RATE*grad\n",
    "\n",
    "            self.list_params_gd.append(W.copy())\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_np = np.c_[np.array(X), np.ones(len(X))].T\n",
    "        W = self.list_params_gd[-1]\n",
    "        return np.round(sigm(X_np, W))\n",
    "    \n",
    "    \n",
    "    #accuracy\n",
    "    def score(self, X, Y):  \n",
    "        predicts_res = self.predict(X)\n",
    "        tp_tn = 0\n",
    "        fp_fn = 0\n",
    "        for i in range(len(Y)):\n",
    "            if np.array(Y)[i] == predicts_res[i].item():\n",
    "                tp_tn += 1\n",
    "            else:\n",
    "                fp_fn += 1\n",
    "        return tp_tn / (tp_tn + fp_fn)\n",
    "    \n",
    "    \n",
    "    def logloss(self, X,Y,W):\n",
    "        cost = 0\n",
    "        sigm_matr = sigm(X, W)\n",
    "        for i in range(len(Y)):\n",
    "            cost += (Y[i].item() * sigm_matr[i].item() + (1-Y[i].item()) * np.log(1-sigm_matr[i].item()))\n",
    "        return -cost \n",
    "    \n",
    "    #Следующие два метода веротнее всего реализовал неверно (изменения от fit отмечены с комментарием ->->)\n",
    "    \n",
    "    # RMSProp\n",
    "    def fit_RMSProp(self, Y, X, y_nesterov=0.9):\n",
    "        # X + нулевой вес\n",
    "        X_np = np.c_[np.array(X), np.ones(len(X))].T       # X в numpy массив [5x100]\n",
    "        \n",
    "        Y_np = np.asmatrix(Y).T\n",
    "        \n",
    "        # Начальное приближение весов\n",
    "        W = np.random.normal(size=(X_np.shape[0],1), loc=1, scale=0)     # Матричца весов [5x1]\n",
    "        \n",
    "        # создание копии, т.к. иначе будем перезапиывать по ссылке\n",
    "        self.list_params_gd = [W.copy()]\n",
    "        \n",
    "        # ->-> начальные значения накопленного среднего\n",
    "        cumulative_middle_grad = np.zeros(shape=(X_np.shape[0],1))\n",
    "        # ->-> сглаживающий параметр\n",
    "        e = 0.0001\n",
    "        \n",
    "        for _ in range(self.EPOCHS):\n",
    "            predictions = sigm(X_np, W)\n",
    "            self.preds.append(predictions)\n",
    "            \n",
    "            cost = self.logloss(X_np, Y_np, W)\n",
    "            self.costs.append(cost)\n",
    "            \n",
    "            #формулу градиента: взял отсюда https://habr.com/ru/articles/472300/ \n",
    "            grad = X_np*(Y_np - self.sigm(X_np, W))\n",
    "            \n",
    "            # ->->\n",
    "            cumulative_middle_grad = y_nesterov*cumulative_middle_grad + (1-y_nesterov)*np.power(self.LEARNING_RATE*grad, 2)\n",
    "            # ->->\n",
    "            W -= self.LEARNING_RATE*grad/np.sqrt(cumulative_middle_grad+e)\n",
    "\n",
    "            self.list_params_gd.append(W.copy())\n",
    "        \n",
    "    \n",
    "    # Nesterov Accelerated Gradient\n",
    "    def fit_NAG(self, Y, X, y_nesterov=0.9):\n",
    "        # X + нулевой вес\n",
    "        X_np = np.c_[np.array(X), np.ones(len(X))].T       # X в numpy массив [5x100]\n",
    "        \n",
    "        Y_np = np.asmatrix(Y).T\n",
    "        \n",
    "        # Начальное приближение весов\n",
    "        W = np.random.normal(size=(X_np.shape[0],1), loc=1, scale=0)     # Матричца весов [5x1]\n",
    "        \n",
    "        # создание копии, т.к. иначе будем перезапиывать по ссылке\n",
    "        self.list_params_gd = [W.copy()]\n",
    "        \n",
    "        # ->-> начальные значения накопленного среднего\n",
    "        cumulative_middle_grad = np.zeros(shape=(X_np.shape[0],1))\n",
    "        \n",
    "        for _ in range(self.EPOCHS):\n",
    "            predictions = sigm(X_np, W)\n",
    "            self.preds.append(predictions)\n",
    "            \n",
    "            cost = self.logloss(X_np, Y_np, W)\n",
    "            self.costs.append(cost)\n",
    "            \n",
    "            #формулу градиента: взял отсюда https://habr.com/ru/articles/472300/\n",
    "            grad = X_np*(Y_np - self.sigm(X_np, W))\n",
    "            \n",
    "            # ->->\n",
    "            cumulative_middle_grad = y_nesterov*cumulative_middle_grad + self.LEARNING_RATE*grad\n",
    "            # ->->\n",
    "            W -= cumulative_middle_grad\n",
    "\n",
    "            self.list_params_gd.append(W.copy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e865c10",
   "metadata": {},
   "source": [
    "## Load iris dataset. There are 2 classes: Versicolor(0) and Virginica(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2b223162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "50                7.0               3.2                4.7               1.4   \n",
       "51                6.4               3.2                4.5               1.5   \n",
       "52                6.9               3.1                4.9               1.5   \n",
       "53                5.5               2.3                4.0               1.3   \n",
       "54                6.5               2.8                4.6               1.5   \n",
       "\n",
       "    species  \n",
       "50        0  \n",
       "51        0  \n",
       "52        0  \n",
       "53        0  \n",
       "54        0  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target\n",
    "df = df[(df['species'] == 1) | (df['species'] == 2)]\n",
    "df['species'] = df['species'].replace(to_replace= [1, 2], value = [0, 1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54865371",
   "metadata": {},
   "source": [
    "### Creating test and data sets. Using own LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d24169d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.75\n"
     ]
    }
   ],
   "source": [
    "X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "Y = df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(epoches=20, learning_rate=0.001)\n",
    "logreg.fit(y_train, X_train)\n",
    "\n",
    "predict = logreg.predict(X_test)\n",
    "print('accuracy ', logreg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d22ae0",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "46396c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.4\n"
     ]
    }
   ],
   "source": [
    "X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "Y = df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(epoches=20, learning_rate=0.001)\n",
    "logreg.fit_NAG(y_train, X_train)\n",
    "\n",
    "predict = logreg.predict(X_test)\n",
    "print('accuracy ', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c5db75",
   "metadata": {},
   "source": [
    "### RMSProp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4bf4c797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.4\n"
     ]
    }
   ],
   "source": [
    "X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
    "Y = df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(epoches=20, learning_rate=0.001)\n",
    "logreg.fit_RMSProp(y_train, X_train)\n",
    "\n",
    "predict = logreg.predict(X_test)\n",
    "print('accuracy ', logreg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c950a25",
   "metadata": {},
   "source": [
    "<b>Реализованы следующие кейсы:</b>\n",
    "- Создан класс Логистической регрессии (аналог от библиотеки SKlearn)\n",
    "- Класс включает реализованные методы: fit, predict, score и прочие вспомогательные.\n",
    "- Класс fit реализует метод отпимизации на основе градиентного спуска.\n",
    "- Дополнительно реализованы методы с продвинутые алгоритмы градиентного спуска: Nesterov Accelerated Gradient и RMSProp\n",
    "\n",
    "<b>Вывод:</b>\n",
    "- не уверен в правильности реализации всех пунктов, работа алгоритма очень сильно может зависить от начальных параметров. Наибольшая accuracy показал алгоритм стандартного градиентного спуска. Время работы у всех трех методов примерно равна.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88cb77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
