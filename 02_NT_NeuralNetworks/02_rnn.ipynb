{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929d9457-0340-4449-9338-4bc72ceb80c3",
   "metadata": {},
   "source": [
    "<b>Task:</b>\n",
    "- Design a POS tagging neural network (POS tagging or part-of-speech tagging - частеречная разметка или автоматическая морфологическая разметка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8053f8c-41ce-4ddc-851d-3bae253b2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1012282c-d23b-4019-9dd0-ddb58a5f6253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading brown: <urlopen error Tunnel connection\n",
      "[nltk_data]     failed: 407 Proxy authentication required>\n",
      "[nltk_data] Error loading universal_tagset: <urlopen error Tunnel\n",
      "[nltk_data]     connection failed: 407 Proxy authentication required>\n"
     ]
    }
   ],
   "source": [
    "# Step 1. load and split data\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ]) # work for numpy == 1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8455c3ed-33ce-4323-89d1-b021e5f1f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090883cc-966c-49b7-a9fa-dec68d3c93c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing data\n",
    "from IPython.display import HTML, display\n",
    "def draw(sentence):\n",
    "    words,tags = zip(*sentence)\n",
    "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
    "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
    "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
    "\n",
    "\n",
    "draw(data[11])\n",
    "draw(data[10])\n",
    "draw(data[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619b77c0-5c4b-4a7a-bb02-c1b845d712b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage = 0.92876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['#EOS#', '#UNK#', 'the', ',', '.', 'of', 'and', 'to', 'a', 'in']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2. Building vocabularies\n",
    "from collections import Counter\n",
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "    \n",
    "    #EOS - \"end of sentence\"\n",
    "    #UNK - \"unknown token\"\n",
    "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
    "\n",
    "#let's measure what fraction of data words are in the dictionary\n",
    "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))\n",
    "\n",
    "all_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd707dc-b2b1-48df-9561-3b2456e1c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Creating collections\n",
    "from collections import defaultdict\n",
    "word_to_id = defaultdict(lambda:1, { word: i for i, word in enumerate(all_words) }) # FOR  defaultdict['ANY_NEW_WORD'] returns 1\n",
    "tag_to_id = { tag: i for i, tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8db239c-2611-4345-890b-dafb441be57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
      "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
      "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
      "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
      "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
      " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
      "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# getting a tensor from dataset by transforming each token into id\n",
    "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
    "    \"\"\"\n",
    "    Converts a list of names into rnn-digestable matrix with paddings added after the end\n",
    "    input:\n",
    "    lines - dataset (words or tags),\n",
    "    token_to_id - collection\n",
    "    max_len - maximum lenght of rows\n",
    "    pad - value for filling\n",
    "    dtype - dtype\n",
    "    time_major - for transpose?\n",
    "    return: tensor\n",
    "    \"\"\"\n",
    "\n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines), max_len],dtype)  # Return a new array of given shape and type, without initializing entries.\n",
    "    matrix.fill(pad)  # Fill the array with a scalar value.\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len] # getting a indexes of each word in a set\n",
    "        matrix[i,:len(line_ix)] = line_ix  # rewriting ones in matrix \n",
    "\n",
    "    return matrix.T if time_major else matrix\n",
    "\n",
    "\n",
    "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "\n",
    "# checking a work of function\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words, word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags, tag_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c630112-78a6-46be-a137-956dca5ee390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          500100    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, None, 64)          7360      \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, None, 14)          910       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 508370 (1.94 MB)\n",
      "Trainable params: 508370 (1.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Build model\n",
    "\n",
    "import keras\n",
    "import keras.layers as L\n",
    "\n",
    "\n",
    "# setting seed for reproducibility\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([None],dtype='int32'))\n",
    "model.add(L.Embedding(len(all_words),50))\n",
    "model.add(L.SimpleRNN(64,return_sequences=True)) # Fully-connected RNN where the output is to be fed back to input.\n",
    "\n",
    "#add top layer that predicts tag probabilities\n",
    "stepwise_dense = L.Dense(len(all_tags),activation='softmax')\n",
    "stepwise_dense = L.TimeDistributed(stepwise_dense) #This wrapper allows to apply a layer to every temporal slice of an input.\n",
    "\"\"\"\n",
    "По умолчанию keras.layers.Dense будет применяться один раз ко всем согласованным шагам времени (Dense would apply once to all time-steps concatenated). \n",
    "Мы используем keras.layers.TimeDistributed для изменения Dense слоя таким образом, \n",
    "чтобы он применялся как по пакетной, так и по временной оси.\n",
    "\"\"\"\n",
    "\n",
    "model.add(stepwise_dense)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773e2154-9148-4bf1-b46d-433e8ec19f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5. Creating generator fun\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences,batch_size=BATCH_SIZE,max_len=None,pad=0):\n",
    "    assert isinstance(sentences,np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "\n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences))) # mixing up of indexes\n",
    "        for start in range(0,len(indices)-1,batch_size):\n",
    "            batch_indices = indices[start:start+batch_size]\n",
    "            batch_words,batch_tags = [],[]\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words,word_to_id,max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags,tag_to_id,max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags,len(all_tags)).reshape(batch_tags.shape+(-1,))\n",
    "            yield batch_words,batch_tags_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9203bdd-4299-4f5d-823f-db4d9db847b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Callbacks\n",
    "def compute_test_accuracy(model):\n",
    "    test_words,test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words,test_tags = to_matrix(test_words,word_to_id),to_matrix(test_tags,tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words,verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags),(test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator)/denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d77debeb-a553-4a01-8a82-0436708a120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1341/1343 [============================>.] - ETA: 0s - loss: 0.2548\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 4s 9ms/step\n",
      "\n",
      "Validation accuracy: 0.94055\n",
      "\n",
      "1343/1343 [==============================] - 22s 15ms/step - loss: 0.2544\n",
      "Epoch 2/5\n",
      "1341/1343 [============================>.] - ETA: 0s - loss: 0.0580\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 4s 8ms/step\n",
      "\n",
      "Validation accuracy: 0.94564\n",
      "\n",
      "1343/1343 [==============================] - 20s 15ms/step - loss: 0.0580\n",
      "Epoch 3/5\n",
      "1340/1343 [============================>.] - ETA: 0s - loss: 0.0513\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 4s 8ms/step\n",
      "\n",
      "Validation accuracy: 0.94656\n",
      "\n",
      "1343/1343 [==============================] - 20s 15ms/step - loss: 0.0514\n",
      "Epoch 4/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0468\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 4s 8ms/step\n",
      "\n",
      "Validation accuracy: 0.94655\n",
      "\n",
      "1343/1343 [==============================] - 21s 16ms/step - loss: 0.0468\n",
      "Epoch 5/5\n",
      "1341/1343 [============================>.] - ETA: 0s - loss: 0.0428\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 4s 8ms/step\n",
      "\n",
      "Validation accuracy: 0.94659\n",
      "\n",
      "1343/1343 [==============================] - 20s 15ms/step - loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e2ccf796a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launching a model\n",
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2312a6a2-e157-4dbf-8004-33b2f12247fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 4s 8ms/step\n",
      "Final accuracy: 0.94659\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"Final accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.94, \"Keras has gone on a rampage again, please contact course staff.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b91ea64-2b4e-409b-bbf1-48ca29617ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embeddings (Embedding)      (None, None, 50)             500100    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " srnn1 (SimpleRNN)           (None, None, 64)             7360      ['embeddings[0][0]']          \n",
      "                                                                                                  \n",
      " srnn2 (SimpleRNN)           (None, None, 64)             7360      ['embeddings[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, None, 128)            0         ['srnn1[0][0]',               \n",
      "                                                                     'srnn2[0][0]']               \n",
      "                                                                                                  \n",
      " timedistributed (TimeDistr  (None, None, 14)             1806      ['concatenate[0][0]']         \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 516626 (1.97 MB)\n",
      "Trainable params: 516626 (1.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 7.1. Bidirectional RNN - first way MANUAL\n",
    "\n",
    "inputs = keras.layers.Input([None], dtype='int32')  # there is Input(return Tensor) insted of InputLayer (return InputLayer)\n",
    "\n",
    "\n",
    "embedding1 = keras.layers.Embedding(len(all_words),50, name='embeddings')(inputs)\n",
    "srnn1 = keras.layers.SimpleRNN(units=64,  name='srnn1', return_sequences=True)(embedding1)  #activation='relu',\n",
    "\n",
    "#embedding2 = keras.layers.Embedding(len(all_words),50, name='embeddings2')(inputs)\n",
    "srnn2 = keras.layers.SimpleRNN(units=64,  name='srnn2', return_sequences=True, go_backwards=True)(embedding1) #go_backwards = True then return reversed sequence\n",
    "\n",
    "concatenated = keras.layers.Concatenate(name='concatenate')([srnn1, srnn2])\n",
    "\n",
    "outputs = keras.layers.Dense(len(all_tags), activation='softmax', name='dense')\n",
    "outputs = keras.layers.TimeDistributed(outputs, name='timedistributed')(concatenated)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc51fe20-43e2-4e01-b3d8-15274db45522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.2274\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 13ms/step\n",
      "\n",
      "Validation accuracy: 0.94112\n",
      "\n",
      "1343/1343 [==============================] - 35s 25ms/step - loss: 0.2273\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0572\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.94479\n",
      "\n",
      "1343/1343 [==============================] - 34s 25ms/step - loss: 0.0572\n",
      "Epoch 3/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0510\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.94545\n",
      "\n",
      "1343/1343 [==============================] - 34s 26ms/step - loss: 0.0510\n",
      "Epoch 4/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0464\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.94519\n",
      "\n",
      "1343/1343 [==============================] - 34s 25ms/step - loss: 0.0464\n",
      "Epoch 5/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0427\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 8s 17ms/step\n",
      "\n",
      "Validation accuracy: 0.94573\n",
      "\n",
      "1343/1343 [==============================] - 36s 27ms/step - loss: 0.0427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e2d1229d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cda94095-adcd-4f42-9b0c-eadfa0e83a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 50)          500100    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, None, 128)         14720     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDi  (None, None, 14)          1806      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 516626 (1.97 MB)\n",
      "Trainable params: 516626 (1.97 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Step 7.2. Bidirectional RNN - second way keras.layers.Bidirectional\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer([None], dtype='int32'))\n",
    "model.add(keras.layers.Embedding(len(all_words), 50))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.SimpleRNN(units=64, return_sequences=True)))\n",
    "\n",
    "stepwise_dense = keras.layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = keras.layers.TimeDistributed(stepwise_dense)\n",
    "\n",
    "model.add(stepwise_dense)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611dde8e-77a9-4a3d-a3cc-64809fb32c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.1879\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.95631\n",
      "\n",
      "1343/1343 [==============================] - 37s 26ms/step - loss: 0.1878\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0419\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.96086\n",
      "\n",
      "1343/1343 [==============================] - 33s 25ms/step - loss: 0.0419\n",
      "Epoch 3/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0348\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.96279\n",
      "\n",
      "1343/1343 [==============================] - 33s 25ms/step - loss: 0.0348\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Validation accuracy: 0.96247\n",
      "\n",
      "1343/1343 [==============================] - 34s 25ms/step - loss: 0.0295\n",
      "Epoch 5/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0249\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 7s 15ms/step\n",
      "\n",
      "Validation accuracy: 0.96145\n",
      "\n",
      "1343/1343 [==============================] - 34s 25ms/step - loss: 0.0249\n",
      "448/448 [==============================] - 6s 14ms/step\n",
      "\n",
      "Final accuracy: 0.96145\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# compiling and getting accuracy\n",
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)\n",
    "\n",
    "\n",
    "# test\n",
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc>0.96, \"Bidirectional RNNs are better than this!\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f92eafe-08f6-4b8a-a1ca-9c2638bbea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2858\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 10s 20ms/step\n",
      "\n",
      "Validation accuracy: 0.95212\n",
      "\n",
      "1343/1343 [==============================] - 50s 35ms/step - loss: 0.2858\n",
      "Epoch 2/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0472\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 9s 20ms/step\n",
      "\n",
      "Validation accuracy: 0.96006\n",
      "\n",
      "1343/1343 [==============================] - 46s 34ms/step - loss: 0.0472\n",
      "Epoch 3/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0382\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 9s 20ms/step\n",
      "\n",
      "Validation accuracy: 0.96329\n",
      "\n",
      "1343/1343 [==============================] - 46s 34ms/step - loss: 0.0381\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 10s 21ms/step\n",
      "\n",
      "Validation accuracy: 0.96469\n",
      "\n",
      "1343/1343 [==============================] - 48s 36ms/step - loss: 0.0329\n",
      "Epoch 5/5\n",
      "1342/1343 [============================>.] - ETA: 0s - loss: 0.0290\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 9s 20ms/step\n",
      "\n",
      "Validation accuracy: 0.96519\n",
      "\n",
      "1343/1343 [==============================] - 46s 35ms/step - loss: 0.0291\n",
      "448/448 [==============================] - 9s 20ms/step\n",
      "\n",
      "Final accuracy: 0.96519\n"
     ]
    }
   ],
   "source": [
    "# Step 8. Experiments\n",
    "# Step 8.1. LSTM experiments\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer([None], dtype='int32'))\n",
    "model.add(keras.layers.Embedding(len(all_words), 50))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=32, return_sequences=True)))  \n",
    "\n",
    "stepwise_dense = keras.layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = keras.layers.TimeDistributed(stepwise_dense)\n",
    "\n",
    "model.add(stepwise_dense)\n",
    "\n",
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)\n",
    "\n",
    "# getting accuracy\n",
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e30e41e2-7626-4b1a-ad9c-61d15a879cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2061\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 27ms/step\n",
      "\n",
      "Validation accuracy: 0.95642\n",
      "\n",
      "1343/1343 [==============================] - 60s 43ms/step - loss: 0.2061\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 26ms/step\n",
      "\n",
      "Validation accuracy: 0.96065\n",
      "\n",
      "1343/1343 [==============================] - 59s 44ms/step - loss: 0.0442\n",
      "Epoch 3/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0379\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 27ms/step\n",
      "\n",
      "Validation accuracy: 0.96189\n",
      "\n",
      "1343/1343 [==============================] - 60s 45ms/step - loss: 0.0379\n",
      "Epoch 4/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0330\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 25ms/step\n",
      "\n",
      "Validation accuracy: 0.96372\n",
      "\n",
      "1343/1343 [==============================] - 58s 43ms/step - loss: 0.0330\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 25ms/step\n",
      "\n",
      "Validation accuracy: 0.96406\n",
      "\n",
      "1343/1343 [==============================] - 56s 42ms/step - loss: 0.0295\n",
      "448/448 [==============================] - 11s 24ms/step\n",
      "\n",
      "Final accuracy: 0.96406\n"
     ]
    }
   ],
   "source": [
    "# Step 8.2. GRU experiments\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer([None], dtype='int32'))\n",
    "model.add(keras.layers.Embedding(len(all_words), 50))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=64, activation='relu', return_sequences=True))) \n",
    "\n",
    "stepwise_dense = keras.layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = keras.layers.TimeDistributed(stepwise_dense)\n",
    "\n",
    "model.add(stepwise_dense)\n",
    "\n",
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)\n",
    "\n",
    "# getting accuracy\n",
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c72a7769-aa70-4ee3-bf99-dcc3fa23d384",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 50)          500100    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 16)          3216      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 32)          1568      \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, None, 128)         37632     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDi  (None, None, 14)          1806      \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 544322 (2.08 MB)\n",
      "Trainable params: 544322 (2.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.1917\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 13s 28ms/step\n",
      "\n",
      "Validation accuracy: 0.95761\n",
      "\n",
      "1343/1343 [==============================] - 65s 46ms/step - loss: 0.1916\n",
      "Epoch 2/10\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 25ms/step\n",
      "\n",
      "Validation accuracy: 0.96152\n",
      "\n",
      "1343/1343 [==============================] - 62s 46ms/step - loss: 0.0408\n",
      "Epoch 3/10\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0329\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 26ms/step\n",
      "\n",
      "Validation accuracy: 0.96254\n",
      "\n",
      "1343/1343 [==============================] - 62s 46ms/step - loss: 0.0329\n",
      "Epoch 4/10\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0280\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 25ms/step\n",
      "\n",
      "Validation accuracy: 0.96164\n",
      "\n",
      "1343/1343 [==============================] - 61s 45ms/step - loss: 0.0280\n",
      "Epoch 5/10\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0242\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 26ms/step\n",
      "\n",
      "Validation accuracy: 0.96182\n",
      "\n",
      "1343/1343 [==============================] - 62s 46ms/step - loss: 0.0242\n",
      "Epoch 6/10\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0216\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 27ms/step\n",
      "\n",
      "Validation accuracy: 0.96110\n",
      "\n",
      "1343/1343 [==============================] - 63s 47ms/step - loss: 0.0216\n",
      "Epoch 7/10\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0193\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 27ms/step\n",
      "\n",
      "Validation accuracy: 0.96104\n",
      "\n",
      "1343/1343 [==============================] - 62s 47ms/step - loss: 0.0193\n",
      "Epoch 8/10\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0176\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 26ms/step\n",
      "\n",
      "Validation accuracy: 0.96092\n",
      "\n",
      "1343/1343 [==============================] - 63s 47ms/step - loss: 0.0176\n",
      "Epoch 9/10\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0161\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 25ms/step\n",
      "\n",
      "Validation accuracy: 0.95896\n",
      "\n",
      "1343/1343 [==============================] - 61s 45ms/step - loss: 0.0161\n",
      "Epoch 10/10\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0146\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 28ms/step\n",
      "\n",
      "Validation accuracy: 0.95992\n",
      "\n",
      "1343/1343 [==============================] - 63s 47ms/step - loss: 0.0146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e2d32e15b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8.3. More layers\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer([None], dtype='int32'))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Embedding(len(all_words), 50))\n",
    "model.add(keras.layers.Conv1D(filters=16, kernel_size=4, activation='relu', padding='same'))\n",
    "#model.add(keras.layers.MaxPooling1D(pool_size=1, padding='same'))\n",
    "model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=64, activation='relu', return_sequences=True))) \n",
    "\n",
    "stepwise_dense = keras.layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = keras.layers.TimeDistributed(stepwise_dense)\n",
    "\n",
    "model.add(stepwise_dense)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=10,)\n",
    "\n",
    "# getting accuracy\n",
    "#acc = compute_test_accuracy(model)\n",
    "#print(\"\\nFinal accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b04b75ec-303f-4991-a9c9-136308b16618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2020\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 14s 31ms/step\n",
      "\n",
      "Validation accuracy: 0.95383\n",
      "\n",
      "1343/1343 [==============================] - 94s 66ms/step - loss: 0.2020\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0475\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 14s 32ms/step\n",
      "\n",
      "Validation accuracy: 0.95959\n",
      "\n",
      "1343/1343 [==============================] - 89s 66ms/step - loss: 0.0475\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0418\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 14s 31ms/step\n",
      "\n",
      "Validation accuracy: 0.96247\n",
      "\n",
      "1343/1343 [==============================] - 88s 66ms/step - loss: 0.0418\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0378\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 14s 32ms/step\n",
      "\n",
      "Validation accuracy: 0.96466\n",
      "\n",
      "1343/1343 [==============================] - 89s 67ms/step - loss: 0.0378\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0347\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 14s 31ms/step\n",
      "\n",
      "Validation accuracy: 0.96554\n",
      "\n",
      "1343/1343 [==============================] - 86s 64ms/step - loss: 0.0347\n",
      "448/448 [==============================] - 14s 31ms/step\n",
      "\n",
      "Final accuracy: 0.96554\n"
     ]
    }
   ],
   "source": [
    "# Step 8.4. Recurrent_dropout + clipnorm\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer([None], dtype='int32'))\n",
    "model.add(keras.layers.Embedding(len(all_words), 50))\n",
    "model.add(keras.layers.Bidirectional(keras.layers.GRU(units=64, activation='relu', recurrent_dropout=0.5, return_sequences=True))) \n",
    "\n",
    "stepwise_dense = keras.layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = keras.layers.TimeDistributed(stepwise_dense)\n",
    "\n",
    "model.add(stepwise_dense)\n",
    "\n",
    "model.compile(keras.optimizers.Adam(clipnorm=1.0),'categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generator=generate_batches(train_data),steps_per_epoch=len(train_data)/BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)\n",
    "\n",
    "# getting accuracy\n",
    "acc = compute_test_accuracy(model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbde3c4-b77e-4f20-849f-18b98b423ff1",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b>\n",
    "\n",
    "| method          | accuracy |\n",
    "|-----------------|----------|\n",
    "|SimpleRNN        |  96%     |\n",
    "|LSTM             |  96%     |\n",
    "|GRU              |  96%     |\n",
    "|More layers      |  96%     |\n",
    "|recurrent_dropout|  96%     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a67c0-b4c9-4c68-a769-a1737ccf0431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}