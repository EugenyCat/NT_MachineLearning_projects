{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45477d01-a89a-4e8d-9302-3c7df258f442",
   "metadata": {},
   "source": [
    "- <b> 1. Some extra </b>\n",
    "- <b> 2. Simple example with TfidfVectorizer, CountVectorizer, NearestNeighbors </b>\n",
    "- <b> 3. Using scipy distances</b>\n",
    "- <b> 4. Surprise library</b>\n",
    "- <b> 5. Implicit ALS (AlternatingLeastSquares)</b>\n",
    "- <b> 6. LightFM library</b>\n",
    "- <b>  </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630335d7-5943-44ba-9fa5-155a10e9abd1",
   "metadata": {},
   "source": [
    "# 1. Some extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f412fa-5c89-4a77-a575-71fc18aaa03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# первая практика из RS , переслушать его комменты\n",
    "\n",
    "film_with_our_mark = []\n",
    "\n",
    "# посчитаем нашу метрику для каждого фильма из датасета\n",
    "for f in title_num_ratings.keys():\n",
    "    film_with_our_mark.append(\n",
    "        # средний_рейитнг_по_фильму * (текущий_рейтинг - средний_рейитнг) / (максимальный - минимальный)\n",
    "        (f, title_mean_rating[f] * (title_num_ratings[f] - mean_num_ratings) / (max_num_ratings - min_num_ratings))\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "film_with_new_mark = []\n",
    "\n",
    "for f in title_num_actions.keys():\n",
    "    # посчитаем нашу новую метрику для каждого фильма из датасета\n",
    "    film_with_new_mark.append(\n",
    "        (f, title_mean_rating[f] * (title_num_actions[f] - mean_num_ratings) / (max_num_ratings - min_num_ratings))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38036d7-3143-45d5-bc4f-9f73f5bfb8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances. cityblock - manhattan distance; cosine - cosines distance\n",
    "from scipy.spatial.distance import cityblock, cosine, euclidean, hamming, jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c77cd-8f59-499b-947c-3aa9c375c595",
   "metadata": {},
   "source": [
    "# 2. Simple example with TfidfVectorizer, CountVectorizer, NearestNeighbors\n",
    "\n",
    "общая идея простая - жанры/теги объединяются в единую строку, прогоняются через CountVectorizer->TfidfTransformer, далее на полученных векторах ищешь ближайших соседей NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7904e6-eb6d-40ec-9dda-0ea8daa49e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. функция удалит пробелы и дефисы, и полученные элементы разобъет по вертикальной линии \n",
    "def change_string(s):\n",
    "    return ' '.join(s.replace(' ', '').replace('-', '').split('|'))\n",
    "\n",
    "movie_genres = movies.genres.apply(change_string).tolist()\n",
    "\n",
    "# 2. прогон строки через CountVectorizer и TfidfTransformer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(movie_genres)\n",
    "count_vect.vocabulary_\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "count_vect.vocabulary_\n",
    "\n",
    "\n",
    "# 3. Обучение ML модели\n",
    "neigh = NearestNeighbors(n_neighbors=7, n_jobs=-1, metric='euclidean')\n",
    "neigh.fit(X_train_tfidf)\n",
    "\n",
    "\n",
    "# 4. Создание тестовой строки и поиск рекомендаций\n",
    "test = change_string(\"Adventure|Comedy|Fantasy|Crime\")\n",
    "\n",
    "predict = count_vect.transform([test])\n",
    "X_tfidf2 = tfidf_transformer.transform(predict)\n",
    "\n",
    "res = neigh.kneighbors(X_tfidf2, return_distance=True)\n",
    "movies.iloc[res[1][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460552c-8209-4e32-872c-fd63fb4e3bc3",
   "metadata": {},
   "source": [
    "# 3. Using scipy distances\n",
    "for creating:\n",
    "- item-to-item collaborative filtering\n",
    "- user-based collaborative filtering\n",
    "- item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa1a804-fd9e-4399-9634-6858e58b1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances. cityblock - manhattan distance; cosine - cosines distance\n",
    "from scipy.spatial.distance import cityblock, cosine, euclidean, hamming, jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99739e52-5334-4c4a-83bc-91437efb8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get vectors describe movies\n",
    "movie_vector = {}\n",
    "\n",
    "for movie, group in tqdm(movies_with_ratings.groupby('title')):\n",
    "    movie_vector[movie] = np.zeros(num_users) #init by zeros\n",
    "    \n",
    "    for i in range(len(group.userId.values)):\n",
    "        u = group.userId.values[i] # user index\n",
    "        r = group.rating.values[i] # which rating user gave to movie\n",
    "        movie_vector[movie][int(u - 1)] = r\n",
    "\n",
    "\n",
    "# 2. want to know which films are similar on 'Fight Club (1999)' using user's ratings\n",
    "my_fav_film = 'Fight Club (1999)'\n",
    "\n",
    "titles = []\n",
    "distances = []\n",
    "\n",
    "for key in tqdm(movie_vector.keys()):\n",
    "    \n",
    "    if key == my_fav_film:\n",
    "        continue\n",
    "    \n",
    "    titles.append(key)\n",
    "    distances.append(cosine(movie_vector[my_fav_film], movie_vector[key])) \n",
    "\n",
    "\n",
    "# 3. print result\n",
    "len(distances)\n",
    "best_indexes = np.argsort(distances)[:10]  # индексы фильмов с наименьшей дистанцией\n",
    "best_indexes\n",
    "\n",
    "# print the max minimum films\n",
    "best_movies = [(titles[i], distances[i]) for i in best_indexes]\n",
    "\n",
    "for m in best_movies:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52cee62-01f1-4cce-972d-cbabd4a3e007",
   "metadata": {},
   "source": [
    "# 4. Surprise library\n",
    "\n",
    "## https://surpriselib.com/\n",
    "### install 1. conda\n",
    "conda install -c conda-forge scikit-surprise\n",
    "\n",
    "### install 2. библиотека surprise - является надстройкой над sklearn\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137f2489-edf4-4dc0-ada8-ef6c2dd9af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans, KNNBasic # Алгоритмы для поиска ближайших соседей (должны быть также другие)\n",
    "from surprise import Dataset # в dataset надо передать пандовский объект в определенном формате\n",
    "from surprise import accuracy # \n",
    "from surprise import Reader # Reader - объект который считаывает датасет и превращает его в объект билиотеки surprise\n",
    "from surprise.model_selection import train_test_split # \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd4f3ec-0158-4df5-827c-1a0a1671a1bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movies_with_ratings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1. Init data - preparing special data format for surprise \u001b[39;00m\n\u001b[1;32m      2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mmovies_with_ratings\u001b[49m\u001b[38;5;241m.\u001b[39muserId,  \u001b[38;5;66;03m# user-id field (must have)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miid\u001b[39m\u001b[38;5;124m'\u001b[39m: movies_with_ratings\u001b[38;5;241m.\u001b[39mtitle,   \u001b[38;5;66;03m# object (item) identifier (must have)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m: movies_with_ratings\u001b[38;5;241m.\u001b[39mrating \u001b[38;5;66;03m# interaction (must have)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m })\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movies_with_ratings' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Init data - preparing special data format for surprise \n",
    "dataset = pd.DataFrame({\n",
    "    'uid': movies_with_ratings.userId,  # user-id field (must have)\n",
    "    'iid': movies_with_ratings.title,   # object (item) identifier (must have)\n",
    "    'rating': movies_with_ratings.rating # interaction (must have)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a20d19-1f21-4625-b01d-3cd7b5dbecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max and min ratings for settings of system\n",
    "min_rating = ratings.rating.min()\n",
    "max_rating = ratings.rating.max()\n",
    "\n",
    "\n",
    "# инициализация Ридера, куда передаем макс и минимальный рейтинг. Далее передаем в Dataset ридер и датафрейм\n",
    "# init Reader\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))  # Reader object input includs Min and Max ratings. \n",
    "data = Dataset.load_from_df(dataset, reader)   # Dataset obj gets dataset in a cpecial format and prepared reader obj\n",
    "\n",
    "\n",
    "# split to test and train\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d9d8b-ec1d-4488-93d5-0efbea00a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. user_based \n",
    "# init algorithm\n",
    "algo = KNNWithMeans(k=50, sim_options={\n",
    "    'name': 'cosine',  # distance (also pearson_baseline)\n",
    "    'user_based': True  #True - for User-based, False - for Item-based\n",
    "})\n",
    "# fit algorithm\n",
    "algo.fit(trainset)\n",
    "\n",
    "# get pred for test\n",
    "test_pred = algo.test(testset)\n",
    "# count rmse\n",
    "accuracy.rmse(test_pred, verbose=True)\n",
    "\n",
    "test_pred[:10] # r_ui - real rating; est - predict rating\n",
    "\n",
    "algo.predict(uid=2, iid='Fight Club (1999)')\n",
    "algo.predict(uid=2, iid='Fight Club (1999)').r_ui # real rating from user 2\n",
    "algo.predict(uid=2, iid='Fight Club (1999)').est # what rating user 2 might give for the film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df02914-bf45-411c-8ed7-88b966699912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. item_based\n",
    "# init algorithm\n",
    "algo = KNNWithMeans(k=50, sim_options={\n",
    "    'name': 'cosine',\n",
    "    'user_based': False  # compute similarities between items\n",
    "})\n",
    "# fit algorithm\n",
    "algo.fit(trainset)\n",
    "\n",
    "# get pred for test\n",
    "test_pred = algo.test(testset)\n",
    "\n",
    "# count rmse\n",
    "accuracy.rmse(test_pred, verbose=True)\n",
    "\n",
    "new_pred = algo.predict(uid=2, iid='Fight Club (1999)')\n",
    "new_pred\n",
    "\n",
    "trainset.global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54e914b-c096-4da1-8ff4-b3bafbd31609",
   "metadata": {},
   "source": [
    "<b> Ready function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008e93d-d4dc-487c-861c-2bbb98d48272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic fnction\n",
    "def generate_recommendation(uid, model, dataset, thresh=4, amount=5):\n",
    "    all_titles = list(dataset['iid'].values)\n",
    "    users_seen_titles = dataset[dataset['uid'] == uid]['iid']\n",
    "    titles = np.array(list(set(all_titles) - set(users_seen_titles)))\n",
    "\n",
    "    np.random.shuffle(titles)\n",
    "    \n",
    "    rec_list = []\n",
    "    for title in titles:\n",
    "        review_prediction = model.predict(uid=uid, iid=title)\n",
    "        rating = review_prediction.est\n",
    "\n",
    "        if rating >= thresh:\n",
    "            rec_list.append((title, round(rating, 2)))\n",
    "            \n",
    "            if len(rec_list) >= amount:\n",
    "                return rec_list\n",
    "\n",
    "generate_recommendation(2, algo, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c1b096-88ac-44e3-9c5a-6da102344d83",
   "metadata": {},
   "source": [
    "# 5. Implicit ALS (AlternatingLeastSquares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555205e-f734-48c0-a0ff-8a5f0377d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implicit package - выполняет implicit als (метод AlternatingLeastSquares)\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "# sparse matrix - разряженная матрица - метод хранения матрица у которой большая часть элементов равна нулям\n",
    "import scipy.sparse as sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff427c3-5d4c-44d6-8b99-f3048c40023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## создадим разряженную матрицу sparse matrix\n",
    "\n",
    "# проассоциируем строчки с юзерами, а столбцы с артистами\n",
    "rows = data.user_id.astype(int)\n",
    "cols = data.artist_id.astype(int)\n",
    "\n",
    "# собираем sparse матрицы , куда передаем (взаимодейсвтие и (строчки, столбцы ) - это как бы индексы)\n",
    "data_sparse = sparse.csr_matrix((plays, (rows, cols)), shape=(len(users),len(artists)))\n",
    "\n",
    "## перевод в \"большой вид\"\n",
    "userid = [0,10]\n",
    "user_items = data_sparse.T.tocsr()[userid]\n",
    "user_items[0][:10].todense()\n",
    "np.array(items)[0][:10]\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e86af07-3ff8-462a-9717-3e5a02771de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Init ALS model and fit modeo on sparse matrix\n",
    "model = AlternatingLeastSquares(factors=50)\n",
    "model.fit(data_sparse.T) # транспонирование - чтоб рекомендовать юзерам песни, а не песням юзеров  (немного контринтуитивно)\n",
    "\n",
    "\n",
    "## 1. get and show recommendations (персональная для юзера)\n",
    "userid = 1111\n",
    "recommendations = model.recommend(userid, data_sparse[userid]) # чтоб получить рекомендацию, надо в модель передать ЮзерID и то что юзер уже слушал\n",
    "\n",
    "for r in recommendations[0]:\n",
    "    print(artist_id_name[str(r)]) # artist_id_name - dict соответсвия artist_id и artist_name\n",
    "\n",
    "\n",
    "## 2. get and show recommendations (по выбронному item показать похожие)\n",
    "itemid = 252494\n",
    "related = model.similar_items(itemid)\n",
    "\n",
    "for a in related[0]:\n",
    "    print(artist_id_name[str(a)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa9f86-b327-4af2-b150-44650d19bfab",
   "metadata": {},
   "source": [
    "# 6. LightFM library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8cdf3-4cf0-48d5-a37d-27520a1e01f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a built-in dataset \"fetch_movielens\"\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf6dd98-f788-4f23-a334-6979051e23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init data. fetch_movielens() returns dict\n",
    "movielens = fetch_movielens()\n",
    "\n",
    "# get splitted data for constructing rs model \n",
    "train = movielens['train']\n",
    "test = movielens['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08478ceb-ed5d-448a-bf1a-2f00812cc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightfm package\n",
    "from lightfm import LightFM # basic class for fitting and predictions \n",
    "from lightfm.evaluation import precision_at_k # precision at k is a measure of how many of the top k recommended items are relevant.\n",
    "from lightfm.evaluation import auc_score # calculates the Area Under the Curve score for the recommendations. The AUC is a measure of the model's ability to rank relevant items higher than irrelevant items.\n",
    "\n",
    "\n",
    "# attempt 1\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10) # fit from \"zero\"\n",
    "#model.fit_partial(train, epochs=10) # fit_partial - continue optimization from \"reached point\"\n",
    "\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "\n",
    "# train_interactions=train - These items won't be counted when calculating the score to prevent suggesting items the user already knows about.\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean() \n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision)) # isn't good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13959e64-b2ec-45c3-8811-13505f2a5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "    n_users, n_items = data['train'].shape\n",
    "    for user_id in user_ids:\n",
    "        # list of positives values \n",
    "        known_positives = data['item_labels'][data['train'].tocsr()                                    \n",
    "                          [user_id].indices]\n",
    "        \n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "\n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "        \n",
    "        print(\"     Recommended:\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "sample_recommendation(model, movielens, [10, 25, 451])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
