{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c549edb0-b837-4d04-8bc1-284ad6d52bd3",
   "metadata": {},
   "source": [
    "# 1. Box Cox and Derivation\n",
    "# 2. Test Dickey-Fuller\n",
    "# 3. Autocorrelation plot\n",
    "# 4. Moving Average \n",
    " - ## 4.1. Simple\n",
    "- ## 4.2. Weighted Moving Average\n",
    "- ## 4.3. Exponential Moving Average\n",
    "- ## 4.4. Double Exponential Moving Average\n",
    "- ## 4.5. Holt-Winters\n",
    "# 5. How to define the params for Holt-Winters\n",
    "# 6. Cross-validation in time series\n",
    "# 7.\n",
    "# 8.\n",
    "# 9.\n",
    "# 10.\n",
    "# 11.\n",
    "# 12.\n",
    "# 13.\n",
    "# 14.\n",
    "# 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09e1d0-34eb-48ec-abeb-bb64e30f1bd0",
   "metadata": {},
   "source": [
    "# 1. Box Cox and Derivation (for getting a stationary time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa08909-8a39-4795-a12f-01a76606a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Box Cox Преобразование Бокса-Кокса часто применяется для нормализации данных или для стабилизации дисперсии\n",
    "from scipy.stats import boxcox  \n",
    "from scipy.special import inv_boxcox # для обратного преобразования\n",
    "\n",
    "all_series = {\n",
    "    \"Monthly sales of company X\": sales_of_company_x[\"Count\"],\n",
    "    \"International airline passengers: monthly totals in thousands\": airlines_passengers[\"Count\"]\n",
    "}\n",
    "\n",
    "# boxcox(x, lmbda=None, alpha=None)  lmbda (необязательный)  - степень трансформации;  alpha: (необязательный) уровень значимости для доверительного интервала lmbda. \n",
    "series = boxcox(\n",
    "    x=all_series[\"International airline passengers: monthly totals in thousands\"], \n",
    "    lmbda=0,\n",
    "    alpha=None\n",
    ")\n",
    "\n",
    "\n",
    "inv = inv_boxcox(series, lmbda=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d68ad-cb01-4775-8d96-d2b945acbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Derivation\n",
    "import numpy as np \n",
    "\n",
    "# np.diff для вычисления разностей между элементами массива вдоль указанной оси. \n",
    "# для анализа временных рядов, вычисления производных или обнаружения изменений между последовательными значениями.\n",
    "# np.diff(a, n=1, axis=-1) n: (по умолчанию 1) количество разностей, которые нужно вычислить. Например, n=2 вернет разности второго порядка.\n",
    "# axis: (по умолчанию -1) ось, вдоль которой вычисляются разности.\n",
    "series = np.diff(series, 1)\n",
    "\n",
    "\n",
    "# or \n",
    "series = series[1:] - series[:-1]\n",
    "# or\n",
    "series = series[12:] - series[:-12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94800ef-8d9d-4483-bfc9-7d91e647374d",
   "metadata": {},
   "source": [
    "# 2. Test Dickey-Fuller (to test if the time series is stationary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e88f4-ede1-45c6-9572-781b3f76072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "adfuller(x, maxlag=None, regression='c', autolag='AIC', store=False, regresults=False)\n",
    "# x: список, массив NumPy или серия pandas с временным рядом.\n",
    "# maxlag: максимальное количество лагов\n",
    "# regression: тип регрессии: тут 'c' для включения константы но есть и много других напр., 'ctt' для включения константы, линейного и квадратичного трендов,\n",
    "# autolag: метод автоматического выбора лагов, тут 'AIC' для критерия Акаике\n",
    "# store: если True, возвращает дополнительные результаты в виде класса с атрибутами.\n",
    "# regresults: если True, сохраняет результаты промежуточной регрессии.\n",
    "\n",
    "\n",
    "dftest = adfuller(timeseries, autolag='AIC')\n",
    "\n",
    "\n",
    "# example of method\n",
    "################\n",
    " # Dickey-Fuller\n",
    "##################\n",
    "def test_stationarity(timeseries):\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for [key, value] in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "# call method\n",
    "test_stationarity(all_series[\"International airline passengers: monthly totals in thousands\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f7241-8564-482a-b840-9b73e1b4a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! HELPER METHOD for defining the seasonality SEASONALITY\n",
    "def plot_ts_and_points(ts, start_point, step):\n",
    "    new_series = [None for i in range(len(ts))]\n",
    "    for i in range(len(ts)):\n",
    "        pos = start_point + step * i\n",
    "        if pos >= len(ts):\n",
    "            break\n",
    "        new_series[pos] = ts[pos]\n",
    "    new_series = pd.Series(new_series)\n",
    "    \n",
    "    with plt.style.context('bmh'):\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        ts_ax = plt.axes()\n",
    "        ts.plot(ax=ts_ax, color='blue')\n",
    "        new_series.plot(ax=ts_ax, style='ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53390f3-697e-4849-8647-ea1ca6bd7b99",
   "metadata": {},
   "source": [
    "# 3. Autocorrelation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b3a32-e397-4b78-9a0f-512e1c91f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "# statsmodels.api предоставляет высокоуровневый доступ ко всем функциям библиотеки statsmodels. Обычно используется для общей статистики и моделирования.\n",
    "# statsmodels.tsa.api предоставляет доступ к функциям и классам, специфичным для анализа временных рядов. \n",
    "# Это включает в себя модели ARIMA, тесты на стационарность, функции для построения автокорреляционных графиков и многое другое.\n",
    "\n",
    "# plot_acf - Автокорреляционная функция - идентифицирует зависимость значений временного ряда на разных лагах.\n",
    "smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05)\n",
    "\n",
    "# plot_pacf - Частичная автокорреляционная функция - показывает корреляцию значений временного ряда с лагами, устранение влияния промежуточных лагах.\n",
    "smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05)\n",
    "\n",
    "\n",
    "#  метод для построения коррелорграммы \n",
    "def tsplot(y, lags=None, figsize=(14, 8), style='bmh'):\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style):\n",
    "        plt.figure(figsize=figsize)\n",
    "        layout = (4, 1)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), rowspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (2, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (3, 0))\n",
    "\n",
    "        y.plot(ax=ts_ax, color='blue', label='Or')\n",
    "        ts_ax.set_title('Original')\n",
    "\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    return\n",
    "\n",
    "\n",
    "tsplot(all_series[\"International airline passengers: monthly totals in thousands\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da733479-0ffa-41c9-a932-30c29aa01cee",
   "metadata": {},
   "source": [
    "# 4. Moving Average \n",
    "\n",
    "## 4.1.\n",
    "$\\hat{y}_{t} = \\frac{1}{k} \\displaystyle\\sum^{k-1}_{n=0} y_{t-n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a468c68-ce9f-4155-810b-f3c6527e74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. method for calc the moving average\n",
    "def moving_average(series, n):\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    return series.rolling(n).mean()\n",
    "\n",
    "# call moving_average with the window equals 7\n",
    "ser = moving_average(sales_of_company_x[\"Count\"], 7)\n",
    "\n",
    "\n",
    "# 2. predict value using the moving average approach \n",
    "def predict(series, N, n_pred):\n",
    "    new_series = series.copy()\n",
    "    len_series = len(series)\n",
    "    for _ in range(n_pred):\n",
    "        new_series[len_series+_] = int(pd.Series([new_series[-N:].mean()]))\n",
    "    return new_series\n",
    "\n",
    "# predict next 50 points \n",
    "series_pred = predict(sales_of_company_x[\"Count\"], 7, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237cd60-941c-483b-9f5f-fa1f946f73a6",
   "metadata": {},
   "source": [
    "## 4.2. Weighted Moving Average\n",
    "\n",
    "$\\hat{y}_{t} = \\displaystyle\\sum^{k}_{n=1} \\omega_n y_{t+1-n}$\n",
    "\n",
    "$\\displaystyle\\sum^{k}_{n=1} {\\omega_n} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee46a02-bc2a-48b0-bb32-7a5a3ee4e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for calc the weighted moving average\n",
    "def weighted_moving_average(series, n, weights):\n",
    "    if not isinstance(weights, np.ndarray):\n",
    "        weights = np.array(weights)\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    wma = series.rolling(n).apply(lambda s: (s * weights).sum() / weights.sum(), raw=True) # тут / weights.sum() чтоб сделать веса (0,1]\n",
    "    return wma\n",
    "\n",
    "\n",
    "# call weighted_moving_average with the window equals 7 and weights = [1,1,2,3,5,8,13]\n",
    "wma = weighted_moving_average(sales_of_company_x[\"Count\"], 7, [1,1,2,3,5,8,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac2a2c-9632-4fe1-9287-a57ba3abb8e4",
   "metadata": {},
   "source": [
    "# 4.3. Exponential Moving Average\n",
    "$\\hat{y}_{t} = \\alpha \\cdot y_t + (1-\\alpha) \\cdot \\hat y_{t-1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22152f36-8e06-41df-bbda-ffcfab090987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. method for calc the exponential moving average\n",
    "def exponential_moving_average(series, alpha):\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return pd.Series(result)\n",
    "\n",
    "# call exponential_moving_average with the alpha equals 0.2\n",
    "ema = exponential_moving_average(sales_of_company_x[\"Count\"], 0.2)\n",
    "\n",
    "\n",
    "# 2. method exponential_moving_average + Predictions \n",
    "def exponential_moving_average(series, alpha, n_pred=None):\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n-1] + (1 - alpha) * result[n-1])\n",
    "    if not n_pred:\n",
    "        return pd.Series(result)\n",
    "\n",
    "    len_series = len(series)\n",
    "    predictions = [alpha * series[len_series - 1] + (1 - alpha) * result[-1]]\n",
    "\n",
    "    for _ in range(n_pred):\n",
    "        res = alpha * predictions[-1] + (1 - alpha) * result[-1]\n",
    "        result.append(res)\n",
    "        predictions.append(res)\n",
    "        series[len_series+_] = res\n",
    "    \n",
    "    return series, pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf06bb-4908-4826-b153-9b7fed43be39",
   "metadata": {},
   "source": [
    "# 4.4. Double Exponential Moving Average\n",
    "$\\hat{y}_t=l_t + s_t$\n",
    "\n",
    "$\\hat{y}_t=\\alpha y_t + (1-\\alpha)\\hat{y}_{t-1}$\n",
    "\n",
    "$\\hat{l}_t = \\alpha y_t + (1-\\alpha)(l_{t-1} + s_{t-1})$\n",
    "\n",
    "$l_t = \\alpha y_t + (1-\\alpha)(l_{t-1} + s_{t-1})$\n",
    "\n",
    "$s_t = \\beta (l_t - l_{t-1}) + (1 - \\beta) s_{t-1}$\n",
    "\n",
    "<b> настройка параметров $\\alpha$ и $\\beta$ и  может порой давать самые причудливые результаты. $\\alpha$ отвечает за сглаживание ряда вокруг тренда, $\\beta$ - за сглаживание самого тренда. Чем больше значения, тем более значимыми будут последние наблюдения и менее значимой будет история."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48200c-b91e-4f22-9b86-671875f19f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. method for calc the double exponential moving average\n",
    "def double_ema(series, alpha, beta):\n",
    "    result = [series[0]]\n",
    "    level, trend = series[0], series[1] - series[0]\n",
    "    for n in range(1, len(series)):\n",
    "        value = series[n]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "    return pd.Series(result)\n",
    "\n",
    "\n",
    "# for plot graph \n",
    "def plot_dema(alpha, beta):\n",
    "    dema = double_ema(sales_of_company_x[\"Count\"], alpha, beta)\n",
    "    with plt.style.context('bmh'):\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.plot(sales_of_company_x[\"Count\"], color='blue',label='original')\n",
    "        plt.plot(dema, color='red', linewidth='4', label='DEMA')\n",
    "        plt.title(\"alpha={}, beta={}\".format(alpha, beta))\n",
    "        plt.legend()\n",
    "\n",
    "# calling method plot_dema\n",
    "plot_dema(0.2, 0.2)\n",
    "\n",
    "\n",
    "# 2. method exponential_moving_average + Predictions \n",
    "def double_ema_with_preds(series, alpha, beta, n_preds):\n",
    "    result = [series[0]]\n",
    "    level, trend = series[0], series[1] - series[0]\n",
    "    for n in range(1, len(series)):\n",
    "        value = series[n]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "\n",
    "    len_series = len(series)\n",
    "    preds = []\n",
    "    for n in range(n_preds):\n",
    "        value = result[-1]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "        preds.append(level+trend)\n",
    "        series[len_series+n] = level+trend\n",
    "\n",
    "    return series, pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc2853-0e4d-40fc-be9e-c9b76260a4da",
   "metadata": {},
   "source": [
    "# 4.5. Holt-Winters\n",
    "### Важно - метод применим только в случае сезонности. Если ее нет - метод хольта-винтерса не даст хороших результатов;\n",
    "\n",
    "$l_t = \\alpha(y_t - p_{t-\\tau}) + (1-\\alpha)(l_{t-1} + s_{t-1})$\n",
    "\n",
    "\n",
    "$s_t = \\beta(l_t - l_{t-1}) + (1-\\beta)s_{t-1}$\n",
    "\n",
    "$p_t = \\gamma(y_t - l_t) + (1-\\gamma)p_{t-\\tau}$\n",
    "\n",
    "$\\hat{y}_{t+m} = l_x + s_t + p_{t-\\tau+1+(m-1)mod\\tau}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c2ad3-b4fa-43b9-bea5-a7bddbb81f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_trend(series, season_len):\n",
    "    \"\"\"\n",
    "    This function calculates the initial trend of the time series. \n",
    "    The trend is the average of the differences between each value and the value season_len steps before it, normalized by season_len.\n",
    "    \"\"\"\n",
    "    return sum([float(series[i + season_len] - series[i]) / season_len]) / season_len\n",
    "\n",
    "\n",
    "def initial_seasonal_components(series, slen):\n",
    "    \"\"\"\n",
    "    It iterates over each season, calculates the average, and then determines how much each point deviates from these averages.\n",
    "    \n",
    "    inputs:\n",
    "        seasonals stores the seasonal components.\n",
    "        season_averages stores the average of each season.\n",
    "    \"\"\"\n",
    "    seasonals = {}\n",
    "    season_averages = []\n",
    "    n_seasons = int(len(series)/slen)\n",
    "    # compute season averages\n",
    "    for j in range(n_seasons):\n",
    "        season_averages.append(sum(series[slen*j:slen*j+slen])/float(slen))\n",
    "    # compute initial values\n",
    "    for i in range(slen):\n",
    "        sum_of_vals_over_avg = 0.0\n",
    "        for j in range(n_seasons):\n",
    "            sum_of_vals_over_avg += series[slen*j+i]-season_averages[j]\n",
    "        seasonals[i] = sum_of_vals_over_avg/n_seasons\n",
    "    return seasonals\n",
    "\n",
    "\n",
    "def triple_exponential_smoothing(series, slen, alpha, beta, gamma, n_preds):\n",
    "    \"\"\"\n",
    "    The function initializes the smoothed value, trend, and seasonal components, \n",
    "    then iterates over the time series to update these values using the smoothing equations. \n",
    "    It forecasts future values by extending the series and applying the trend and seasonal components.\n",
    "\n",
    "    inputs:\n",
    "        series is the time series data.\n",
    "        slen is the length of a season (e.g., 12 for monthly data with yearly seasonality).\n",
    "        alpha, beta, and gamma are the smoothing parameters.\n",
    "        n_preds is the number of future points to predict.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    seasonals = initial_seasonal_components(series, slen)\n",
    "    for i in range(len(series)+n_preds):\n",
    "        if i == 0: # initial values\n",
    "            smooth = series[0]\n",
    "            trend = initial_trend(series, slen)\n",
    "            result.append(series[0])\n",
    "            continue\n",
    "        if i >= len(series): # we are forecasting\n",
    "            m = i - len(series) + 1\n",
    "            result.append((smooth + m*trend) + seasonals[i%slen])\n",
    "        else:\n",
    "            val = series[i]\n",
    "            last_smooth, smooth = smooth, alpha*(val-seasonals[i%slen]) + (1-alpha)*(smooth+trend)\n",
    "            trend = beta * (smooth-last_smooth) + (1-beta)*trend\n",
    "            seasonals[i%slen] = gamma*(val-smooth) + (1-gamma)*seasonals[i%slen]\n",
    "            result.append(smooth+trend+seasonals[i%slen])\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_tema(alpha, beta, gamma, ser=sales_of_company_x[\"Count\"], ser_to_plot=sales_of_company_x[\"Count\"], n_preds=24):\n",
    "    tema = triple_exponential_smoothing(ser, 12, alpha, beta, gamma, n_preds)\n",
    "    with plt.style.context('bmh'):\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.plot(ser_to_plot, color='blue',label='original')\n",
    "        plt.plot(tema, color='red', linewidth='4', label='TEMA')\n",
    "        plt.title(\"alpha={}, beta={}, gamma={}\".format(alpha, beta, gamma))\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "plot_tema(0.1, 0.1, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab73752-de49-4cb6-9464-c6a264cfe8cd",
   "metadata": {},
   "source": [
    "# 5. How to define the params for Holt-Winters\n",
    "$RMSE =  \\sqrt {1/n \\sum^N_{i=1} (\\hat{y}_i - y_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68101aa7-b501-4d9a-80ab-0e9cddd2b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Init data\n",
    "series = sales_of_company_x[\"Count\"]\n",
    "train, test, val = series[:60], series[60:70], series[70:]\n",
    "\n",
    "\n",
    "# Create scoring method \n",
    "def mse(X):\n",
    "    alpha, beta, gamma = X\n",
    "    result = triple_exponential_smoothing(train, 12, alpha, beta, gamma, len(test)) # triple_exponential_smoothing (see case 4.5.)\n",
    "    predictions = result[-len(test):]\n",
    "    error = mean_squared_error(predictions, test)\n",
    "    return error\n",
    "\n",
    "# Call the minimize from scipy for looking for optimize alpha, beta and gamma\n",
    "opt = minimize(mse, x0=[0,0,0], method=\"L-BFGS-B\", bounds = ((0, 1), (0, 1), (0, 1)))\n",
    "\n",
    "# Get opt perams \n",
    "alpha_opt, beta_opt, gamma_opt = opt.x\n",
    "print(opt)\n",
    "\n",
    "# Use gotten params in plot_tema (see case 4.5.)\n",
    "plot_tema(alpha_opt, beta_opt, gamma_opt, ser=train, ser_to_plot=series[:70], n_preds=len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90242a8-d79d-44e7-93c1-fce1f72d63fa",
   "metadata": {},
   "source": [
    "# 6. Cross-validation in time series\n",
    "\n",
    "Проблема кросс-валидации на временных рядах состоит в том, что случайно перемешивать в фолдах значения всего ряда нельзя. Т.к. он имеет временную структуру, и ее надо сохранять (иначе потеряются все взаимосвязи наблюдений);\n",
    "\n",
    "Будем делать кросс-валидацию на скользящем окне.\n",
    "\n",
    "Суть достаточно проста:\n",
    "\n",
    "Берем t измерений\n",
    "Делаем прогноз на n измерений вперед и считаем ошибку\n",
    "Берем t+n измерений\n",
    "Делаем прогноз на n измерений вперед и считаем ошибку\n",
    "Берем t+2*n измерений\n",
    "Делаем прогноз на n измерений вперед и считаем ошибку ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b41a75-e3cc-43dd-956a-eb229c874a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.optimize import minimize \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Init data\n",
    "train, val = series[:65], series[65:]\n",
    "\n",
    "# Create scoring method with cross-validation\n",
    "def mse_cross_val(X):\n",
    "    alpha, beta, gamma = X\n",
    "    split = TimeSeriesSplit(n_splits=3) \n",
    "    errors = []\n",
    "    \n",
    "    for train_split, test_split in split.split(train):\n",
    "        train_split_ts = train.iloc[train_split]\n",
    "        test_split_ts = train.iloc[test_split]\n",
    "#         print(train_split_ts)\n",
    "#         print(test_split_ts)\n",
    "        result = triple_exponential_smoothing(train_split_ts, 12, alpha, beta, gamma, len(test_split)) # triple_exponential_smoothing (see case 4.5.)\n",
    "        predictions = result[-len(test_split_ts):]\n",
    "        error = mean_squared_error(predictions, test_split_ts)\n",
    "        errors.append(error)\n",
    "    print(f'{np.mean(np.array(errors))}------------')\n",
    "    return np.mean(np.array(errors))\n",
    "\n",
    "\n",
    "# Call the minimize from scipy for looking for optimize alpha, beta and gamma\n",
    "opt = minimize(mse_cross_val, x0=[0,0,0], method=\"Nelder-Mead\", bounds = ((0, 1), (0, 1), (0, 1)))\n",
    "\n",
    "# Get opt perams \n",
    "alpha_opt, beta_opt, gamma_opt = opt.x\n",
    "print(opt)\n",
    "\n",
    "# Use gotten params in plot_tema (see case 4.5.)\n",
    "plot_tema(alpha_opt, beta_opt, gamma_opt, ser=train, ser_to_plot=series, n_preds=len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6757b-766b-4810-8073-2bc2fa1c97d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67beb30-82fe-43e9-8301-ea5e399c5530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f1c23-bb02-428d-b1a6-4b0a9fab60dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344ba5a-6054-4b9a-8606-938eb33f6bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff6cc1-5551-42cd-9411-cf1e092a77c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3241d2b-7d0a-4730-92b9-dddca37e7049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16262b6-5dd3-4e55-9f2b-e3c10da33cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2a56f-4698-407c-a294-e7b30c090966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
