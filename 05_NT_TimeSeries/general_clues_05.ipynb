{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c549edb0-b837-4d04-8bc1-284ad6d52bd3",
   "metadata": {},
   "source": [
    "# 0. Generating some time series\n",
    "# 1. Box Cox and Derivation\n",
    "# 2. Test Dickey-Fuller\n",
    "# 3. Autocorrelation plot\n",
    "# 4. Moving Average \n",
    " - ## 4.1. Simple\n",
    "- ## 4.2. Weighted Moving Average\n",
    "- ## 4.3. Exponential Moving Average\n",
    "- ## 4.4. Double Exponential Moving Average\n",
    "- ## 4.5. Holt-Winters\n",
    "# 5. How to define the params for Holt-Winters\n",
    "# 6. Cross-validation in time series\n",
    "# 7. models AR, ARMA, ARIMA etc\n",
    "# 8. models ARCH, GARCH\n",
    "# 9. Forecast using classic ML\n",
    "# 10.\n",
    "# 11.\n",
    "# 12.\n",
    "# 13.\n",
    "# 14.\n",
    "# 15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe4a46-daac-4864-b29e-57f68e8f99c9",
   "metadata": {},
   "source": [
    "# 0. Generating some time series\n",
    "- $y_t = E$\n",
    "- $y_t = y_{t-1} + \\epsilon_{t}$\n",
    "- $y_t = c + \\sum_{i=1}^P a_i y_{t-i} + \\epsilon_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60ff77-4472-4103-8902-22033dbf52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. noise\n",
    "randser = np.random.normal(size=1000)\n",
    "\n",
    "\n",
    "#_______________\n",
    "# 2. Random Walk\n",
    "# Random Walk way 1\n",
    "n_samples = 100\n",
    "eps = np.random.normal(size=n_samples)\n",
    "x = [0 + eps[0]]\n",
    "for i in range(1, n_samples):\n",
    "    x.append(x[i-1] + eps[i])\n",
    "\n",
    "\n",
    "\n",
    "# Random Walk way 2\n",
    "x = np.random.normal(size=1000)\n",
    "x = np.cumsum(x) # cumsum - кумулятивная сумма [1, 2, 3, 4] -> [1, 3, 6, 10]\n",
    "\n",
    "\n",
    "\n",
    "#_______________\n",
    "# 3. AR simulation - регрессия второго порядка\n",
    "np.random.seed(1)\n",
    "n_samples = int(1000)\n",
    "a1 = 0.6 # вес для лага 1 (t-1)\n",
    "a2 = 0.3 # вес для лага 2 (t-2)\n",
    "c = 0\n",
    "\n",
    "x = w = np.random.normal(size=n_samples)\n",
    "\n",
    "# регрессия второго порядка\n",
    "for t in range(n_samples):\n",
    "    x[t] = a1*x[t-1] + a2*x[t-2] + w[t] + c\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#_______________\n",
    "# 4. statsmodels provides the function 'arma_generate_sample' to generate random samples from an autoregressive moving average (ARMA) model. \n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "\n",
    "max_lag = 30\n",
    "\n",
    "n = int(5000) # lots of samples to help estimates (\"много образцов для помощи в оценках\")\n",
    "burn = int(n/10) # number of samples to discard before fit\n",
    "\n",
    "alphas = np.array([0.5, -0.25])\n",
    "betas = np.array([0.5, -0.3])\n",
    "ar = np.r_[1, -alphas] # объединенине массивов [1] и [0.5, -0.25]\n",
    "ma = np.r_[1, betas]\n",
    "\n",
    "arma22 = arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09e1d0-34eb-48ec-abeb-bb64e30f1bd0",
   "metadata": {},
   "source": [
    "# 1. Box Cox and Derivation (for getting a stationary time series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa08909-8a39-4795-a12f-01a76606a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Box Cox Преобразование Бокса-Кокса часто применяется для нормализации данных или для стабилизации дисперсии\n",
    "from scipy.stats import boxcox  \n",
    "from scipy.special import inv_boxcox # для обратного преобразования\n",
    "\n",
    "all_series = {\n",
    "    \"Monthly sales of company X\": sales_of_company_x[\"Count\"],\n",
    "    \"International airline passengers: monthly totals in thousands\": airlines_passengers[\"Count\"]\n",
    "}\n",
    "\n",
    "# boxcox(x, lmbda=None, alpha=None)  lmbda (необязательный)  - степень трансформации;  alpha: (необязательный) уровень значимости для доверительного интервала lmbda. \n",
    "series = boxcox(\n",
    "    x=all_series[\"International airline passengers: monthly totals in thousands\"], \n",
    "    lmbda=0,\n",
    "    alpha=None\n",
    ")\n",
    "\n",
    "\n",
    "inv = inv_boxcox(series, lmbda=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d68ad-cb01-4775-8d96-d2b945acbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Derivation\n",
    "import numpy as np \n",
    "\n",
    "# np.diff для вычисления разностей между элементами массива вдоль указанной оси. \n",
    "# для анализа временных рядов, вычисления производных или обнаружения изменений между последовательными значениями.\n",
    "# np.diff(a, n=1, axis=-1) n: (по умолчанию 1) количество разностей, которые нужно вычислить. Например, n=2 вернет разности второго порядка.\n",
    "# axis: (по умолчанию -1) ось, вдоль которой вычисляются разности.\n",
    "series = np.diff(series, 1)\n",
    "\n",
    "\n",
    "# or \n",
    "series = series[1:] - series[:-1]\n",
    "# or\n",
    "series = series[12:] - series[:-12]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbc378-7277-4069-8375-dd662af7b647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of reverting values into original way\n",
    "init_list = [1,4,2,5,2,2]\n",
    "init_list_bx = boxcox(init_list, 0)\n",
    "init_list_diff = np.diff(init_list_bx, 1)\n",
    "\n",
    "# Inverse operation for diff\n",
    "initial_value = init_list_bx[0]\n",
    "rev_dif = np.insert(np.cumsum(init_list_diff)+[initial_value]*len(init_list_diff), 0, initial_value)\n",
    "\n",
    "# Inverse operation for Box-Cox\n",
    "rev_bx = inv_boxcox(rev_dif, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94800ef-8d9d-4483-bfc9-7d91e647374d",
   "metadata": {},
   "source": [
    "# 2. Test Dickey-Fuller (to test if the time series is stationary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e88f4-ede1-45c6-9572-781b3f76072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "adfuller(x, maxlag=None, regression='c', autolag='AIC', store=False, regresults=False)\n",
    "# x: список, массив NumPy или серия pandas с временным рядом.\n",
    "# maxlag: максимальное количество лагов\n",
    "# regression: тип регрессии: тут 'c' для включения константы но есть и много других напр., 'ctt' для включения константы, линейного и квадратичного трендов,\n",
    "# autolag: метод автоматического выбора лагов, тут 'AIC' для критерия Акаике\n",
    "# store: если True, возвращает дополнительные результаты в виде класса с атрибутами.\n",
    "# regresults: если True, сохраняет результаты промежуточной регрессии.\n",
    "\n",
    "\n",
    "dftest = adfuller(timeseries, autolag='AIC')\n",
    "\n",
    "\n",
    "# example of method\n",
    "################\n",
    " # Dickey-Fuller\n",
    "##################\n",
    "def test_stationarity(timeseries):\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for [key, value] in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "# call method\n",
    "test_stationarity(all_series[\"International airline passengers: monthly totals in thousands\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31470f7-46c5-4f2b-968b-c67c54075ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **!!** HELPER METHOD for plotting\n",
    "# helper method that calls test_stationarity() and plot Autocorrelation and Quantil-Quantil graph\n",
    "def tsplot(y, lags=None, figsize=(14, 8), style='bmh'):\n",
    "    plt.clf()\n",
    "    test_stationarity(y)\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style):\n",
    "        plt.figure(figsize=figsize)\n",
    "        layout = (5, 1)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), rowspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (2, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (3, 0))\n",
    "        qq_ax = plt.subplot2grid(layout, (4, 0))\n",
    "\n",
    "        y.plot(ax=ts_ax, color='blue', label='Or')\n",
    "        ts_ax.set_title('Original')\n",
    "\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05) # автокорреляция\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05) # частичная автокорреляция\n",
    "        sm.qqplot(y, line='s', ax=qq_ax) # график квантиль-квантиль\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f7241-8564-482a-b840-9b73e1b4a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **!!** HELPER METHOD for defining the seasonality SEASONALITY\n",
    "def plot_ts_and_points(ts, start_point, step):\n",
    "    plt.clf()\n",
    "    if not isinstance(ts, pd.Series):\n",
    "        ts = pd.Series(ts)\n",
    "    new_series = [None for i in range(len(ts))]\n",
    "    for i in range(len(ts)):\n",
    "        pos = start_point + step * i\n",
    "        if pos >= len(ts):\n",
    "            break\n",
    "        new_series[pos] = ts[pos]\n",
    "    new_series = pd.Series(new_series)\n",
    "    \n",
    "    with plt.style.context('bmh'):\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        ts_ax = plt.axes()\n",
    "        ts.plot(ax=ts_ax, color='blue')\n",
    "        new_series.plot(ax=ts_ax, style='ro')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53390f3-697e-4849-8647-ea1ca6bd7b99",
   "metadata": {},
   "source": [
    "# 3. Autocorrelation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940b3a32-e397-4b78-9a0f-512e1c91f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "# statsmodels.api предоставляет высокоуровневый доступ ко всем функциям библиотеки statsmodels. Обычно используется для общей статистики и моделирования.\n",
    "# statsmodels.tsa.api предоставляет доступ к функциям и классам, специфичным для анализа временных рядов. \n",
    "# Это включает в себя модели ARIMA, тесты на стационарность, функции для построения автокорреляционных графиков и многое другое.\n",
    "\n",
    "# plot_acf - Автокорреляционная функция - идентифицирует зависимость значений временного ряда на разных лагах.\n",
    "smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05)\n",
    "\n",
    "# plot_pacf - Частичная автокорреляционная функция - показывает корреляцию значений временного ряда с лагами, устранение влияния промежуточных лагах.\n",
    "smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05)\n",
    "\n",
    "\n",
    "#  метод для построения коррелорграммы \n",
    "def tsplot(y, lags=None, figsize=(14, 8), style='bmh'):\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y)\n",
    "    with plt.style.context(style):\n",
    "        plt.figure(figsize=figsize)\n",
    "        layout = (4, 1)\n",
    "        ts_ax = plt.subplot2grid(layout, (0, 0), rowspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (2, 0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (3, 0))\n",
    "\n",
    "        y.plot(ax=ts_ax, color='blue', label='Or')\n",
    "        ts_ax.set_title('Original')\n",
    "\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.05)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.05)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    return\n",
    "\n",
    "\n",
    "tsplot(all_series[\"International airline passengers: monthly totals in thousands\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da733479-0ffa-41c9-a932-30c29aa01cee",
   "metadata": {},
   "source": [
    "# 4. Moving Average \n",
    "\n",
    "## 4.1.\n",
    "$\\hat{y}_{t} = \\frac{1}{k} \\displaystyle\\sum^{k-1}_{n=0} y_{t-n}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a468c68-ce9f-4155-810b-f3c6527e74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. method for calc the moving average\n",
    "def moving_average(series, n):\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    return series.rolling(n).mean()\n",
    "\n",
    "# call moving_average with the window equals 7\n",
    "ser = moving_average(sales_of_company_x[\"Count\"], 7)\n",
    "\n",
    "\n",
    "# 2. predict value using the moving average approach \n",
    "def predict(series, N, n_pred):\n",
    "    new_series = series.copy()\n",
    "    len_series = len(series)\n",
    "    for _ in range(n_pred):\n",
    "        new_series[len_series+_] = int(pd.Series([new_series[-N:].mean()]))\n",
    "    return new_series\n",
    "\n",
    "# predict next 50 points \n",
    "series_pred = predict(sales_of_company_x[\"Count\"], 7, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b237cd60-941c-483b-9f5f-fa1f946f73a6",
   "metadata": {},
   "source": [
    "## 4.2. Weighted Moving Average\n",
    "\n",
    "$\\hat{y}_{t} = \\displaystyle\\sum^{k}_{n=1} \\omega_n y_{t+1-n}$\n",
    "\n",
    "$\\displaystyle\\sum^{k}_{n=1} {\\omega_n} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee46a02-bc2a-48b0-bb32-7a5a3ee4e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for calc the weighted moving average\n",
    "def weighted_moving_average(series, n, weights):\n",
    "    if not isinstance(weights, np.ndarray):\n",
    "        weights = np.array(weights)\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    wma = series.rolling(n).apply(lambda s: (s * weights).sum() / weights.sum(), raw=True) # тут / weights.sum() чтоб сделать веса (0,1]\n",
    "    return wma\n",
    "\n",
    "\n",
    "# call weighted_moving_average with the window equals 7 and weights = [1,1,2,3,5,8,13]\n",
    "wma = weighted_moving_average(sales_of_company_x[\"Count\"], 7, [1,1,2,3,5,8,13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac2a2c-9632-4fe1-9287-a57ba3abb8e4",
   "metadata": {},
   "source": [
    "# 4.3. Exponential Moving Average\n",
    "$\\hat{y}_{t} = \\alpha \\cdot y_t + (1-\\alpha) \\cdot \\hat y_{t-1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22152f36-8e06-41df-bbda-ffcfab090987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. method for calc the exponential moving average\n",
    "def exponential_moving_average(series, alpha):\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return pd.Series(result)\n",
    "\n",
    "# call exponential_moving_average with the alpha equals 0.2\n",
    "ema = exponential_moving_average(sales_of_company_x[\"Count\"], 0.2)\n",
    "\n",
    "\n",
    "# 2. method exponential_moving_average + Predictions \n",
    "def exponential_moving_average(series, alpha, n_pred=None):\n",
    "    result = [series[0]]\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n-1] + (1 - alpha) * result[n-1])\n",
    "    if not n_pred:\n",
    "        return pd.Series(result)\n",
    "\n",
    "    len_series = len(series)\n",
    "    predictions = [alpha * series[len_series - 1] + (1 - alpha) * result[-1]]\n",
    "\n",
    "    for _ in range(n_pred):\n",
    "        res = alpha * predictions[-1] + (1 - alpha) * result[-1]\n",
    "        result.append(res)\n",
    "        predictions.append(res)\n",
    "        series[len_series+_] = res\n",
    "    \n",
    "    return series, pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddf06bb-4908-4826-b153-9b7fed43be39",
   "metadata": {},
   "source": [
    "# 4.4. Double Exponential Moving Average\n",
    "$\\hat{y}_t=l_t + s_t$\n",
    "\n",
    "$\\hat{y}_t=\\alpha y_t + (1-\\alpha)\\hat{y}_{t-1}$\n",
    "\n",
    "$\\hat{l}_t = \\alpha y_t + (1-\\alpha)(l_{t-1} + s_{t-1})$\n",
    "\n",
    "$l_t = \\alpha y_t + (1-\\alpha)(l_{t-1} + s_{t-1})$\n",
    "\n",
    "$s_t = \\beta (l_t - l_{t-1}) + (1 - \\beta) s_{t-1}$\n",
    "\n",
    "<b> настройка параметров $\\alpha$ и $\\beta$ и  может порой давать самые причудливые результаты. $\\alpha$ отвечает за сглаживание ряда вокруг тренда, $\\beta$ - за сглаживание самого тренда. Чем больше значения, тем более значимыми будут последние наблюдения и менее значимой будет история."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48200c-b91e-4f22-9b86-671875f19f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. method for calc the double exponential moving average\n",
    "def double_ema(series, alpha, beta):\n",
    "    result = [series[0]]\n",
    "    level, trend = series[0], series[1] - series[0]\n",
    "    for n in range(1, len(series)):\n",
    "        value = series[n]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "    return pd.Series(result)\n",
    "\n",
    "\n",
    "# for plot graph \n",
    "def plot_dema(alpha, beta):\n",
    "    dema = double_ema(sales_of_company_x[\"Count\"], alpha, beta)\n",
    "    with plt.style.context('bmh'):\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.plot(sales_of_company_x[\"Count\"], color='blue',label='original')\n",
    "        plt.plot(dema, color='red', linewidth='4', label='DEMA')\n",
    "        plt.title(\"alpha={}, beta={}\".format(alpha, beta))\n",
    "        plt.legend()\n",
    "\n",
    "# calling method plot_dema\n",
    "plot_dema(0.2, 0.2)\n",
    "\n",
    "\n",
    "# 2. method exponential_moving_average + Predictions \n",
    "def double_ema_with_preds(series, alpha, beta, n_preds):\n",
    "    result = [series[0]]\n",
    "    level, trend = series[0], series[1] - series[0]\n",
    "    for n in range(1, len(series)):\n",
    "        value = series[n]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "\n",
    "    len_series = len(series)\n",
    "    preds = []\n",
    "    for n in range(n_preds):\n",
    "        value = result[-1]\n",
    "        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n",
    "        trend = beta*(level-last_level) + (1-beta)*trend\n",
    "        result.append(level+trend)\n",
    "        preds.append(level+trend)\n",
    "        series[len_series+n] = level+trend\n",
    "\n",
    "    return series, pd.Series(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc2853-0e4d-40fc-be9e-c9b76260a4da",
   "metadata": {},
   "source": [
    "# 4.5. Holt-Winters\n",
    "### Важно - метод применим только в случае сезонности. Если ее нет - метод хольта-винтерса не даст хороших результатов;\n",
    "\n",
    "$l_t = \\alpha(y_t - p_{t-\\tau}) + (1-\\alpha)(l_{t-1} + s_{t-1})$\n",
    "\n",
    "\n",
    "$s_t = \\beta(l_t - l_{t-1}) + (1-\\beta)s_{t-1}$\n",
    "\n",
    "$p_t = \\gamma(y_t - l_t) + (1-\\gamma)p_{t-\\tau}$\n",
    "\n",
    "$\\hat{y}_{t+m} = l_x + s_t + p_{t-\\tau+1+(m-1)mod\\tau}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c2ad3-b4fa-43b9-bea5-a7bddbb81f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_trend(series, season_len):\n",
    "    \"\"\"\n",
    "    This function calculates the initial trend of the time series. \n",
    "    The trend is the average of the differences between each value and the value season_len steps before it, normalized by season_len.\n",
    "    \"\"\"\n",
    "    return sum([float(series[i + season_len] - series[i]) / season_len]) / season_len\n",
    "\n",
    "\n",
    "def initial_seasonal_components(series, slen):\n",
    "    \"\"\"\n",
    "    It iterates over each season, calculates the average, and then determines how much each point deviates from these averages.\n",
    "    \n",
    "    inputs:\n",
    "        seasonals stores the seasonal components.\n",
    "        season_averages stores the average of each season.\n",
    "    \"\"\"\n",
    "    seasonals = {}\n",
    "    season_averages = []\n",
    "    n_seasons = int(len(series)/slen)\n",
    "    # compute season averages\n",
    "    for j in range(n_seasons):\n",
    "        season_averages.append(sum(series[slen*j:slen*j+slen])/float(slen))\n",
    "    # compute initial values\n",
    "    for i in range(slen):\n",
    "        sum_of_vals_over_avg = 0.0\n",
    "        for j in range(n_seasons):\n",
    "            sum_of_vals_over_avg += series[slen*j+i]-season_averages[j]\n",
    "        seasonals[i] = sum_of_vals_over_avg/n_seasons\n",
    "    return seasonals\n",
    "\n",
    "\n",
    "def triple_exponential_smoothing(series, slen, alpha, beta, gamma, n_preds):\n",
    "    \"\"\"\n",
    "    The function initializes the smoothed value, trend, and seasonal components, \n",
    "    then iterates over the time series to update these values using the smoothing equations. \n",
    "    It forecasts future values by extending the series and applying the trend and seasonal components.\n",
    "\n",
    "    inputs:\n",
    "        series is the time series data.\n",
    "        slen is the length of a season (e.g., 12 for monthly data with yearly seasonality).\n",
    "        alpha, beta, and gamma are the smoothing parameters.\n",
    "        n_preds is the number of future points to predict.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    seasonals = initial_seasonal_components(series, slen)\n",
    "    for i in range(len(series)+n_preds):\n",
    "        if i == 0: # initial values\n",
    "            smooth = series[0]\n",
    "            trend = initial_trend(series, slen)\n",
    "            result.append(series[0])\n",
    "            continue\n",
    "        if i >= len(series): # we are forecasting\n",
    "            m = i - len(series) + 1\n",
    "            result.append((smooth + m*trend) + seasonals[i%slen])\n",
    "        else:\n",
    "            val = series[i]\n",
    "            last_smooth, smooth = smooth, alpha*(val-seasonals[i%slen]) + (1-alpha)*(smooth+trend)\n",
    "            trend = beta * (smooth-last_smooth) + (1-beta)*trend\n",
    "            seasonals[i%slen] = gamma*(val-smooth) + (1-gamma)*seasonals[i%slen]\n",
    "            result.append(smooth+trend+seasonals[i%slen])\n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_tema(alpha, beta, gamma, ser=sales_of_company_x[\"Count\"], ser_to_plot=sales_of_company_x[\"Count\"], n_preds=24):\n",
    "    tema = triple_exponential_smoothing(ser, 12, alpha, beta, gamma, n_preds)\n",
    "    with plt.style.context('bmh'):\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.plot(ser_to_plot, color='blue',label='original')\n",
    "        plt.plot(tema, color='red', linewidth='4', label='TEMA')\n",
    "        plt.title(\"alpha={}, beta={}, gamma={}\".format(alpha, beta, gamma))\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "plot_tema(0.1, 0.1, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab73752-de49-4cb6-9464-c6a264cfe8cd",
   "metadata": {},
   "source": [
    "# 5. How to define the params for Holt-Winters\n",
    "$RMSE =  \\sqrt {1/n \\sum^N_{i=1} (\\hat{y}_i - y_i)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68101aa7-b501-4d9a-80ab-0e9cddd2b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Init data\n",
    "series = sales_of_company_x[\"Count\"]\n",
    "train, test, val = series[:60], series[60:70], series[70:]\n",
    "\n",
    "\n",
    "# Create scoring method \n",
    "def mse(X):\n",
    "    alpha, beta, gamma = X\n",
    "    result = triple_exponential_smoothing(train, 12, alpha, beta, gamma, len(test)) # triple_exponential_smoothing (see case 4.5.)\n",
    "    predictions = result[-len(test):]\n",
    "    error = mean_squared_error(predictions, test)\n",
    "    return error\n",
    "\n",
    "# Call the minimize from scipy for looking for optimize alpha, beta and gamma\n",
    "opt = minimize(mse, x0=[0,0,0], method=\"L-BFGS-B\", bounds = ((0, 1), (0, 1), (0, 1)))\n",
    "\n",
    "# Get opt perams \n",
    "alpha_opt, beta_opt, gamma_opt = opt.x\n",
    "print(opt)\n",
    "\n",
    "# Use gotten params in plot_tema (see case 4.5.)\n",
    "plot_tema(alpha_opt, beta_opt, gamma_opt, ser=train, ser_to_plot=series[:70], n_preds=len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90242a8-d79d-44e7-93c1-fce1f72d63fa",
   "metadata": {},
   "source": [
    "# 6. Cross-validation in time series\n",
    "\n",
    "Проблема кросс-валидации на временных рядах состоит в том, что случайно перемешивать в фолдах значения всего ряда нельзя. Т.к. он имеет временную структуру, и ее надо сохранять (иначе потеряются все взаимосвязи наблюдений);\n",
    "\n",
    "Будем делать кросс-валидацию на скользящем окне.\n",
    "\n",
    "Суть достаточно проста:\n",
    "\n",
    "Берем t измерений\n",
    "Делаем прогноз на n измерений вперед и считаем ошибку\n",
    "Берем t+n измерений\n",
    "Делаем прогноз на n измерений вперед и считаем ошибку\n",
    "Берем t+2*n измерений\n",
    "Делаем прогноз на n измерений вперед и считаем ошибку ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b41a75-e3cc-43dd-956a-eb229c874a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.optimize import minimize \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Init data\n",
    "train, val = series[:65], series[65:]\n",
    "\n",
    "# Create scoring method with cross-validation\n",
    "def mse_cross_val(X):\n",
    "    alpha, beta, gamma = X\n",
    "    split = TimeSeriesSplit(n_splits=3) \n",
    "    errors = []\n",
    "    \n",
    "    for train_split, test_split in split.split(train):\n",
    "        train_split_ts = train.iloc[train_split]\n",
    "        test_split_ts = train.iloc[test_split]\n",
    "#         print(train_split_ts)\n",
    "#         print(test_split_ts)\n",
    "        result = triple_exponential_smoothing(train_split_ts, 12, alpha, beta, gamma, len(test_split)) # triple_exponential_smoothing (see case 4.5.)\n",
    "        predictions = result[-len(test_split_ts):]\n",
    "        error = mean_squared_error(predictions, test_split_ts)\n",
    "        errors.append(error)\n",
    "    print(f'{np.mean(np.array(errors))}------------')\n",
    "    return np.mean(np.array(errors))\n",
    "\n",
    "\n",
    "# Call the minimize from scipy for looking for optimize alpha, beta and gamma\n",
    "opt = minimize(mse_cross_val, x0=[0,0,0], method=\"Nelder-Mead\", bounds = ((0, 1), (0, 1), (0, 1)))\n",
    "\n",
    "# Get opt perams \n",
    "alpha_opt, beta_opt, gamma_opt = opt.x\n",
    "print(opt)\n",
    "\n",
    "# Use gotten params in plot_tema (see case 4.5.)\n",
    "plot_tema(alpha_opt, beta_opt, gamma_opt, ser=train, ser_to_plot=series, n_preds=len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cadf986-4ae0-41e2-ace0-45eeb1e8a9c7",
   "metadata": {},
   "source": [
    "# 7. AR, ARMA, ARIMA etc\n",
    "\n",
    "1) <b>AR</b> (Авторегрессионная модель) — модель временных рядов, в которой значения временного ряда в данный момент линейно зависят от предыдущих значений этого же ряда. Авторегрессионный процесс порядка p (AR(p)-процесс) определяется следующим образом\n",
    "\n",
    "$y_t = c + \\sum_{i=1}^P a_i y_{t-i} + \\epsilon_t$\n",
    "\n",
    "где \n",
    "- $c$ - константа \n",
    "- $\\sum_{i=1}^P a_i y_{t-i}$ - сумма взешенных предыдущих значений\n",
    "- $P$ - лаг или порядок авторегрессии AR (сколько шагов назад)\n",
    "- $\\epsilon_t$ - белый шум\n",
    "\n",
    "2) <b>ARMA(p, q)</b> - модель ARMA(p, q) представляет собой соединение двух моделей:\n",
    "- AR(P) - авторегрессии на знанениях временного ряда\n",
    "- MA(q) - скользящее среднее на ошибках первой модели\n",
    "\n",
    "<i>p.s. В statsmodel в последней версии убрали класс ARMA оставив только ARIMA, поэтому тут описание для ARMA но код на ARIMA. </i>\n",
    "\n",
    "<i>p.s.s. По сути модель ARMA можно получить с помощью ARIMA , занулив второй параметр ARIMA(p,d=0,q)</i>\n",
    "\n",
    "AR(p) пытается предсказать \"значение\" временного ряда, а MA(q) пытается поймать шоковые явления, наблюдаемые в оставшемся случайном шуме.\n",
    "\n",
    "$y_t = \\sum_{i=1}^P a_i x_{t-i} + \\sum_{i=1}^Q b_i \\epsilon_{t-i} + \\epsilon_t + c$\n",
    "\n",
    "- $\\sum_{i=1}^P a_i x_{t-i}$ - обычная авторегрессия\n",
    "- $ \\sum_{i=1}^Q b_i \\epsilon_{t-i}$ - скользящее среднее на ошибках AR\n",
    "\n",
    "3) <b>ARIMA</b> - естественное расширение модели ARMA. Как мы уже хорошо знаем - многие временные ряды не стационарны, но они могут такими стать в результате операции дифференцирования. В модели ARIMA \"дифференцирование\" (в количестве d-раз) вносится в саму модель\n",
    "\n",
    "\n",
    "$\\delta^p y_t = c + \\sum_{i=1}^p a_i \\delta^d y_{t-i} + \\sum_{j=1}^q b_j \\epsilon_{t-j} + \\epsilon_t$\n",
    "\n",
    "\n",
    "4) <b>SARIMA</b> - арима с учетом сезонности\n",
    "5) <b>ARIMAX/SARIMAX</b> - ARIMAX использует внешние переменные для объяснения временных изменений в ряду данных, а SARIMAX дополнительно учитывает сезонные колебания, что полезно для данных с регулярными сезонными паттернами и внешними воздействиями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67beb30-82fe-43e9-8301-ea5e399c5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.ar_model as arm     # arm.AutoReg ; arm.ar_select_order\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "from statsmodels.tsa.arima_model import ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f1c23-bb02-428d-b1a6-4b0a9fab60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) AR\n",
    "import statsmodels.tsa.ar_model as arm\n",
    "\n",
    "# The 'arm.AutoReg' class is used to fit an autoregressive model to a time series. \n",
    "mdl = arm.AutoReg(x, lags=3, trend='n').fit()\n",
    "\n",
    "# 'arm.ar_select_order' is used to determine the optimal number of lags based on criteria (like AIC, BIC, etc.).\n",
    "est_order = arm.ar_select_order(x, maxlag=3, trend='n', ic='aic')\n",
    "\n",
    "print('alpha estimate: {}'.format(mdl.params[:len(est_order.ar_lags)]))\n",
    "print('best lag order = {}'.format(len(est_order.ar_lags)))\n",
    "\n",
    "# the optimal number of lags\n",
    "est_order.ar_lags\n",
    "\n",
    "# fitted coefficients\n",
    "mdl.params\n",
    "\n",
    "\n",
    "# resid - вернет значения остатков (из реального time series вычитается предсказанный)\n",
    "# по resid можно построить график остатков (в идеале который должен быть просто линией в нуле)\n",
    "# задача состоит в том, чтоб график остатков был !!стационарен!!, таким образом мы будем знать что мы\n",
    "# вытащили из временного ряда все что можно было)\n",
    "tsplot(mdl.resid, lags=30) # tsplot find upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a344ba5a-6054-4b9a-8606-938eb33f6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) ARMA (p,q) ARIMA(p, d, q)\n",
    "from statsmodels.tsa.arima_model import ARMA # не поддерживается в пользу statsmodels.tsa.arima.model.ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA # I  - значит также проводится дифференцирование \n",
    "\n",
    "\n",
    "# looking for the best params for ARMA or ARIMA using AIC - Информационный критерий Акаике\n",
    "# p, d, q - гипер параметры => их можно подбирать. Как выбрать лучшие? AIC - Информационный критерий Акаике\n",
    "best_aic = np.inf \n",
    "best_order = None\n",
    "best_mdl = None\n",
    "\n",
    "for i in range(5):\n",
    "    for d in range(5):  # for ARMA this param has to be 0\n",
    "        for j in range(5):\n",
    "            try:\n",
    "                tmp_mdl = ARIMA(series, order=(i, d, j), trend='c').fit(method='innovations_mle')\n",
    "                tmp_aic = tmp_mdl.aic\n",
    "                if tmp_aic < best_aic:\n",
    "                    best_aic = tmp_aic\n",
    "                    best_order = (i, d, j)\n",
    "                    best_mdl = tmp_mdl\n",
    "            except: continue\n",
    "\n",
    "\n",
    "print('aic: {:6.5f} | order: {}'.format(best_aic, best_order))\n",
    "\n",
    "\n",
    "tsplot(best_mdl.resid, lags=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ff6cc1-5551-42cd-9411-cf1e092a77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График оригинального (стационарного) ряда , предсказания а также 95% доверительного интервала (интервал где с 95% долей вероятности окажется след. значение)\n",
    "forecast = mdl.get_forecast(steps=20)\n",
    "forecast_values = forecast.predicted_mean\n",
    "confidence_intervals = forecast.conf_int()\n",
    "\n",
    "# Creating an index for the forecasted values\n",
    "forecast_index = np.arange(len(series), len(series) + 20)\n",
    "\n",
    "with plt.style.context(style='bmh'):\n",
    "    plt.figure(figsize=(14,8))\n",
    "    ax = plt.axes()\n",
    "    plt.plot(series, color='red', label='original, stationary') # original\n",
    "    plt.plot(mdl.predict(start=0, end=len(series)+20), color='blue', label='prediction, stationary') # mdl.predict\n",
    "\n",
    "    # Plotting the only forecasted values\n",
    "    #plt.plot(forecast_index, forecast_values, color='blue', label='prediction, stationary')\n",
    "\n",
    "    # Plotting the confidence intervals\n",
    "    plt.fill_between(forecast_index, \n",
    "                     confidence_intervals[:, 0], \n",
    "                     confidence_intervals[:, 1], \n",
    "                     color='blue', alpha=0.2, label='95% confidence intervals')\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59881ccc-9524-494a-9767-fe8a29df2665",
   "metadata": {},
   "source": [
    "# 8. ARCH and GARCH\n",
    "\n",
    "## 1. ARCH - autoregressive conditional heteroskedasticity\n",
    "- <b>ARCH</b> - модель авторегрессии (AR) условной герероскеданичности (CH)\n",
    "\n",
    "<b>AutoRegressive Conditional Heteroscedasticit</b> - пытаемся объяснить дисперсию в ряде через предыдущие значения (применяя к ним AR).\n",
    "- т.е. модель смотрит не просто значения, но также учитывает дисперсию этих значений\n",
    "- этой моделью ставится первичная цель предсказать дисперсию\n",
    "\n",
    "\n",
    "<p></p>\n",
    "\n",
    "- <b>Гетероскедастичность</b> - когда дисперсия временного ряда непостоянна.\n",
    "- <b>Гомоскедастичность</b> - когда дисперсия временного ряда постоянна для всех значений независимых переменных.\n",
    "\n",
    "Пусть временной ряд представляется в таком виде:\n",
    "\n",
    "$u_t = \\epsilon_t * \\sqrt{\\alpha_0 + \\sum_{i=1}^q \\alpha_i u_{t-i}^2}$\n",
    "\n",
    "Тогда условная дисперсия ряда будет равна\n",
    "\n",
    "$\\sigma_t^2 = V(u_t | u_{t-1}, ..., u_{t-q}) = \\alpha_0 + \\sum_{i=1}^q \\alpha_i u_{t-i}^2$\n",
    "\n",
    "Получили модель ARCH(q) условной дисперсии. Требуем, чтобы все коэффициенты были больше 0 (иначе может получится отрицательная дисперсия)\n",
    "\n",
    "## 2. GARCH хорошо учитыавет дисперсию в моделях, где дисперсия ведет себя как временной ряд\n",
    "\n",
    "Добавляем зависимость от прошлых значений самой условной дисперсии. Получаем модель GARCH(p, q)\n",
    "\n",
    "$\\sigma_t^2 = V(u_t | u_{t-1}, ..., u_{t-q}) = \\alpha_0 + \\sum_{i=1}^q \\alpha_i u_{t-i}^2 + \\sum_{j=1}^p \\beta_j \\sigma_{t-j}^2$\n",
    "\n",
    "GARCH - по сути - модель ARMA примененная к дисперсии ряда\n",
    "\n",
    "\n",
    "p.s. <b> Важно отметить, что изученные модели (AR, ARMA, ARIMA, ARCH, GARCH) довольно плохи в предсказании, но с ними можно строить модель или принимать решение на основе доверительных интервалов.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3b518-8c60-4e2a-bab9-a7fa8cab5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16262b6-5dd3-4e55-9f2b-e3c10da33cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the method of looking for the best params\n",
    "\n",
    "def _get_best_model(TS):\n",
    "    best_aic = np.inf \n",
    "    best_order = None\n",
    "    best_mdl = None\n",
    "\n",
    "    for i in range(5):\n",
    "        for d in range(5):\n",
    "            for j in range(5):\n",
    "                try:\n",
    "                    tmp_mdl = arch_model(series, p=i, o=d, q=j, dist='StudentsT').fit(update_freq=5, disp='off') \n",
    "                    #tmp_mdl = ARIMA(TS, order=(i, d, j)).fit(method='innovations_mle') # параметры полученные с помощью ARIMA можно применить и для GARCH\n",
    "                    tmp_aic = tmp_mdl.aic\n",
    "                    if tmp_aic < best_aic:\n",
    "                        best_aic = tmp_aic\n",
    "                        best_order = (i, d, j)\n",
    "                        best_mdl = tmp_mdl\n",
    "                except: continue\n",
    "    print('aic: {:6.5f} | order: {}'.format(best_aic, best_order))                    \n",
    "    return best_aic, best_order, best_mdl\n",
    "\n",
    "\n",
    "aic, order, mdl = _get_best_model(series)\n",
    "\n",
    "# график остатков\n",
    "tsplot(res.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef2a56f-4698-407c-a294-e7b30c090966",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [4,2,4]\n",
    "\n",
    "p_ = order[0]\n",
    "o_ = order[1]\n",
    "q_ = order[2]\n",
    "\n",
    "# Using student T distribution usually provides better fit\n",
    "am = arch_model(new_series, p=p_, o=o_, q=q_, dist='StudentsT')\n",
    "res = am.fit(update_freq=5)\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c793be-841a-4f20-bdde-036e406e51f2",
   "metadata": {},
   "source": [
    "# 9. Forecast using classic ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ef12f-3433-40ca-bcd6-b3a1bd87ca02",
   "metadata": {},
   "source": [
    "### \"По простому\"\n",
    "##### С предсказанием же лучше справится та же Линейная регрессия от sklearn, т.к. в ней реализовано аналитическое решение и она гарантированно вернет лучшее решение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379640e-be19-4d31-9f52-4ed0866af029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def prepareData(data, lag_start=5, lag_end=20, test_size=0.15):\n",
    "    \n",
    "    data = pd.DataFrame(data.copy())\n",
    "    \n",
    "    # считаем индекс в датафрейме, после которого начинается тестовый отрезок\n",
    "    test_index = int(len(data)*(1-test_size))\n",
    "    \n",
    "    # добавляем лаги исходного ряда в качестве признаков\n",
    "    for i in range(lag_start, lag_end):\n",
    "        data[\"lag_{}\".format(i)] = data.Count.shift(i)\n",
    "        \"\"\"\n",
    "                    e.g.\n",
    "                         Month      Count  lag_1   lag_2    lag_3\n",
    "                    0    1949-01    112    NaN     NaN      NaN\n",
    "                    1    1949-02    118    112.0   NaN      NaN\n",
    "                    2    1949-03    132    118.0   112.0    NaN\n",
    "        \"\"\"\n",
    "        \n",
    "    data = data.dropna()\n",
    "    data = data.reset_index(drop=True)\n",
    "    data = data.drop([\"Month\"], axis=1)\n",
    "     \n",
    "    # разбиваем весь датасет на тренировочную и тестовую выборку\n",
    "    X_train = data.loc[:test_index].drop([\"Count\"], axis=1)\n",
    "    y_train = data.loc[:test_index][\"Count\"]\n",
    "    X_test = data.loc[test_index:].drop([\"Count\"], axis=1)\n",
    "    y_test = data.loc[test_index:][\"Count\"]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepareData(series, lag_start=1, lag_end=20, test_size=0.3)\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "prediction = lr.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(prediction, \"r\", label=\"prediction\")\n",
    "plt.plot(y_test.values, label=\"actual\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Linear regression\")\n",
    "plt.grid(True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
